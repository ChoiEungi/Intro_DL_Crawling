{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STEP 1 필요한 모듈 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.models import load_model\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager   # 한글 사용을 위해서 임포트 \n",
    "import pandas as pd\n",
    "import numpy\n",
    "import tensorflow as tf\n",
    "\n",
    "# 실행할 때마다 같은 결과를 출력하기 위해 설정하는 부분\n",
    "seed=0\n",
    "numpy.random.seed(3)\n",
    "tf.random.set_seed(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STEP 2 분석할 데이터 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0   1   2    3    4   5   6    7   8    9   10  11  12  13\n",
      "1    63   1   3  145  233   1   0  150   0  2.3   0   0   1   1\n",
      "2    37   1   2  130  250   0   1  187   0  3.5   0   0   2   1\n",
      "3    41   0   1  130  204   0   0  172   0  1.4   2   0   2   1\n",
      "4    56   1   1  120  236   0   1  178   0  0.8   2   0   2   1\n",
      "5    57   0   0  120  354   0   1  163   1  0.6   2   0   2   1\n",
      "..   ..  ..  ..  ...  ...  ..  ..  ...  ..  ...  ..  ..  ..  ..\n",
      "299  57   0   0  140  241   0   1  123   1  0.2   1   0   3   0\n",
      "300  45   1   3  110  264   0   1  132   0  1.2   1   0   3   0\n",
      "301  68   1   0  144  193   1   1  141   0  3.4   1   2   3   0\n",
      "302  57   1   0  130  131   0   1  115   1  1.2   1   1   3   0\n",
      "303  57   0   1  130  236   0   0  174   0  0.0   1   1   2   0\n",
      "\n",
      "[303 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "#csv파일에서 문자열이 있어 읽기 어려움. --> pandas에서 문자열을 제거 후 numpy로 변환\n",
    "df = pd.read_csv('C:/ai/dataset/heart.csv',header=None)\n",
    "df = df.drop(0,0)\n",
    "df= df.apply(pd.to_numeric,errors='coerce').fillna(0)\n",
    "print(df)\n",
    "\n",
    "#pandas를 numpy로 변환\n",
    "dataset=df.values\n",
    "\n",
    "X = dataset[:,0:13]\n",
    "Y = dataset[:,13]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STEP 3 모델 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('heart_model1.h5') \n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 25)                350       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 15)                390       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 16        \n",
      "=================================================================\n",
      "Total params: 756\n",
      "Trainable params: 756\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary() # 모델 간단히 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STEP 4 모델 실행하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 5.0822 - accuracy: 0.4752 - val_loss: 3.4032 - val_accuracy: 0.4754\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 2.5207 - accuracy: 0.4835 - val_loss: 2.0163 - val_accuracy: 0.5082\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.7840 - accuracy: 0.5207 - val_loss: 1.3761 - val_accuracy: 0.5246\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.5307 - accuracy: 0.5785 - val_loss: 2.2256 - val_accuracy: 0.5902\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.5008 - accuracy: 0.5992 - val_loss: 1.1642 - val_accuracy: 0.6066\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.1142 - accuracy: 0.6157 - val_loss: 0.9780 - val_accuracy: 0.6393\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.0561 - accuracy: 0.6198 - val_loss: 0.8686 - val_accuracy: 0.7049\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.9255 - accuracy: 0.6777 - val_loss: 0.8321 - val_accuracy: 0.6721\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.1080 - accuracy: 0.5620 - val_loss: 0.8680 - val_accuracy: 0.6393\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.8311 - accuracy: 0.6818 - val_loss: 1.2890 - val_accuracy: 0.4918\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.8400 - accuracy: 0.6777 - val_loss: 0.6928 - val_accuracy: 0.7049\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.7241 - accuracy: 0.6736 - val_loss: 0.8733 - val_accuracy: 0.6721\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.7536 - accuracy: 0.6736 - val_loss: 0.6830 - val_accuracy: 0.7377\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6098 - accuracy: 0.7397 - val_loss: 0.6011 - val_accuracy: 0.7541\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5704 - accuracy: 0.7645 - val_loss: 0.5797 - val_accuracy: 0.7213\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6213 - accuracy: 0.7314 - val_loss: 0.7215 - val_accuracy: 0.7049\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5686 - accuracy: 0.7479 - val_loss: 0.7024 - val_accuracy: 0.7049\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6015 - accuracy: 0.6983 - val_loss: 0.6401 - val_accuracy: 0.7541\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4939 - accuracy: 0.7645 - val_loss: 0.5427 - val_accuracy: 0.7705\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5467 - accuracy: 0.7355 - val_loss: 0.8555 - val_accuracy: 0.6230\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5929 - accuracy: 0.7190 - val_loss: 0.6413 - val_accuracy: 0.7541\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5626 - accuracy: 0.7562 - val_loss: 0.5895 - val_accuracy: 0.7705\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4365 - accuracy: 0.8099 - val_loss: 0.5220 - val_accuracy: 0.7705\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4803 - accuracy: 0.7645 - val_loss: 0.5839 - val_accuracy: 0.7705\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4588 - accuracy: 0.8017 - val_loss: 0.5659 - val_accuracy: 0.7377\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4451 - accuracy: 0.7934 - val_loss: 0.5187 - val_accuracy: 0.7541\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6850 - accuracy: 0.6818 - val_loss: 0.6793 - val_accuracy: 0.7541\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.7927 - accuracy: 0.6736 - val_loss: 0.7449 - val_accuracy: 0.6557\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4848 - accuracy: 0.7851 - val_loss: 0.5446 - val_accuracy: 0.7377\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4475 - accuracy: 0.7851 - val_loss: 0.5361 - val_accuracy: 0.7541\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4944 - accuracy: 0.7645 - val_loss: 0.5664 - val_accuracy: 0.7377\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5143 - accuracy: 0.7851 - val_loss: 0.5322 - val_accuracy: 0.7705\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4756 - accuracy: 0.7851 - val_loss: 0.5093 - val_accuracy: 0.8033\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5015 - accuracy: 0.7769 - val_loss: 0.4971 - val_accuracy: 0.7705\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5945 - accuracy: 0.7397 - val_loss: 0.6205 - val_accuracy: 0.7705\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4450 - accuracy: 0.7769 - val_loss: 1.0591 - val_accuracy: 0.5082\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5165 - accuracy: 0.7645 - val_loss: 0.6744 - val_accuracy: 0.7541\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.7168 - accuracy: 0.6942 - val_loss: 0.5416 - val_accuracy: 0.7705\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5195 - accuracy: 0.7438 - val_loss: 0.5339 - val_accuracy: 0.7705\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6282 - accuracy: 0.7438 - val_loss: 0.5118 - val_accuracy: 0.7869\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6239 - accuracy: 0.7355 - val_loss: 0.7252 - val_accuracy: 0.6721\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5815 - accuracy: 0.7355 - val_loss: 0.5578 - val_accuracy: 0.7541\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5258 - accuracy: 0.7893 - val_loss: 0.4878 - val_accuracy: 0.7705\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4128 - accuracy: 0.7934 - val_loss: 0.8633 - val_accuracy: 0.5738\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5478 - accuracy: 0.7438 - val_loss: 0.9324 - val_accuracy: 0.6393\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5661 - accuracy: 0.7521 - val_loss: 0.5360 - val_accuracy: 0.7541\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4893 - accuracy: 0.7438 - val_loss: 0.5291 - val_accuracy: 0.7705\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4118 - accuracy: 0.8223 - val_loss: 0.4869 - val_accuracy: 0.7541\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4563 - accuracy: 0.7893 - val_loss: 1.0940 - val_accuracy: 0.6066\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4405 - accuracy: 0.7934 - val_loss: 0.4845 - val_accuracy: 0.7541\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4572 - accuracy: 0.7727 - val_loss: 0.5290 - val_accuracy: 0.7869\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5580 - accuracy: 0.7397 - val_loss: 1.2310 - val_accuracy: 0.4754\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.8925 - accuracy: 0.6570 - val_loss: 1.3424 - val_accuracy: 0.4754\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4815 - accuracy: 0.7893 - val_loss: 0.7364 - val_accuracy: 0.6721\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4841 - accuracy: 0.7934 - val_loss: 0.7491 - val_accuracy: 0.7705\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5483 - accuracy: 0.7851 - val_loss: 0.5234 - val_accuracy: 0.7869\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4144 - accuracy: 0.8140 - val_loss: 0.5347 - val_accuracy: 0.7705\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3997 - accuracy: 0.8140 - val_loss: 0.4895 - val_accuracy: 0.7705\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3867 - accuracy: 0.8140 - val_loss: 0.5740 - val_accuracy: 0.7541\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.8182 - val_loss: 0.5020 - val_accuracy: 0.8197\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4077 - accuracy: 0.8223 - val_loss: 0.4871 - val_accuracy: 0.7705\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4109 - accuracy: 0.8264 - val_loss: 0.5034 - val_accuracy: 0.7705\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4286 - accuracy: 0.7975 - val_loss: 0.5334 - val_accuracy: 0.8197\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4481 - accuracy: 0.7810 - val_loss: 0.5133 - val_accuracy: 0.8033\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5150 - accuracy: 0.7727 - val_loss: 0.4769 - val_accuracy: 0.7705\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.5035 - accuracy: 0.7645 - val_loss: 0.5405 - val_accuracy: 0.8033\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3968 - accuracy: 0.8430 - val_loss: 0.6019 - val_accuracy: 0.7541\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7934 - val_loss: 0.5399 - val_accuracy: 0.8033\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4815 - accuracy: 0.8306 - val_loss: 0.6143 - val_accuracy: 0.7705\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6133 - accuracy: 0.7521 - val_loss: 0.4947 - val_accuracy: 0.8197\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3961 - accuracy: 0.8140 - val_loss: 0.4767 - val_accuracy: 0.7869\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4119 - accuracy: 0.7810 - val_loss: 1.0576 - val_accuracy: 0.5082\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6234 - accuracy: 0.7521 - val_loss: 0.4632 - val_accuracy: 0.7869\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4902 - accuracy: 0.7851 - val_loss: 0.5903 - val_accuracy: 0.7377\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5559 - accuracy: 0.7851 - val_loss: 0.4844 - val_accuracy: 0.7869\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3660 - accuracy: 0.8264 - val_loss: 0.9802 - val_accuracy: 0.5738\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5424 - accuracy: 0.7562 - val_loss: 0.5106 - val_accuracy: 0.8033\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4433 - accuracy: 0.8347 - val_loss: 0.4906 - val_accuracy: 0.7869\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4226 - accuracy: 0.8471 - val_loss: 0.6340 - val_accuracy: 0.7705\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4745 - accuracy: 0.8058 - val_loss: 0.5856 - val_accuracy: 0.7377\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.7041 - accuracy: 0.7397 - val_loss: 0.7000 - val_accuracy: 0.7705\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4425 - accuracy: 0.8058 - val_loss: 0.4940 - val_accuracy: 0.8033\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4870 - accuracy: 0.7851 - val_loss: 0.4659 - val_accuracy: 0.8033\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4239 - accuracy: 0.8306 - val_loss: 0.4863 - val_accuracy: 0.8361\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4457 - accuracy: 0.8306 - val_loss: 0.6431 - val_accuracy: 0.7705\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5528 - accuracy: 0.7603 - val_loss: 0.4590 - val_accuracy: 0.8033\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4174 - accuracy: 0.7975 - val_loss: 0.8661 - val_accuracy: 0.5902\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.8044 - accuracy: 0.6942 - val_loss: 0.5688 - val_accuracy: 0.7377\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4630 - accuracy: 0.8058 - val_loss: 0.4917 - val_accuracy: 0.8033\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4714 - accuracy: 0.8058 - val_loss: 0.4566 - val_accuracy: 0.7869\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4677 - accuracy: 0.8099 - val_loss: 0.4963 - val_accuracy: 0.8197\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4097 - accuracy: 0.8264 - val_loss: 0.4750 - val_accuracy: 0.7705\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3973 - accuracy: 0.8264 - val_loss: 0.5073 - val_accuracy: 0.8197\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4829 - accuracy: 0.7810 - val_loss: 0.5263 - val_accuracy: 0.8033\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5874 - accuracy: 0.7066 - val_loss: 0.5769 - val_accuracy: 0.7541\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3988 - accuracy: 0.8471 - val_loss: 0.6034 - val_accuracy: 0.7705\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4732 - accuracy: 0.8058 - val_loss: 0.5501 - val_accuracy: 0.8033\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5788 - accuracy: 0.7727 - val_loss: 0.6887 - val_accuracy: 0.6557\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4376 - accuracy: 0.8264 - val_loss: 0.5590 - val_accuracy: 0.7869\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4282 - accuracy: 0.8182 - val_loss: 0.8322 - val_accuracy: 0.6066\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4219 - accuracy: 0.7851 - val_loss: 0.6336 - val_accuracy: 0.7705\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3906 - accuracy: 0.8306 - val_loss: 0.5591 - val_accuracy: 0.7377\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4289 - accuracy: 0.8017 - val_loss: 0.5360 - val_accuracy: 0.7869\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4177 - accuracy: 0.8264 - val_loss: 0.4511 - val_accuracy: 0.7869\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4817 - accuracy: 0.8017 - val_loss: 0.4532 - val_accuracy: 0.8033\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5839 - accuracy: 0.7479 - val_loss: 0.7237 - val_accuracy: 0.6557\n",
      "Epoch 107/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4379 - accuracy: 0.8264 - val_loss: 0.4567 - val_accuracy: 0.7869\n",
      "Epoch 108/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4019 - accuracy: 0.8099 - val_loss: 0.4794 - val_accuracy: 0.8033\n",
      "Epoch 109/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6050 - accuracy: 0.7769 - val_loss: 1.2391 - val_accuracy: 0.4918\n",
      "Epoch 110/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.5351 - accuracy: 0.7934 - val_loss: 0.5671 - val_accuracy: 0.7869\n",
      "Epoch 111/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4510 - accuracy: 0.8017 - val_loss: 0.4955 - val_accuracy: 0.8197\n",
      "Epoch 112/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4993 - accuracy: 0.7810 - val_loss: 0.5587 - val_accuracy: 0.7869\n",
      "Epoch 113/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.9910 - accuracy: 0.6983 - val_loss: 0.5910 - val_accuracy: 0.7869\n",
      "Epoch 114/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4237 - accuracy: 0.8306 - val_loss: 0.4575 - val_accuracy: 0.8033\n",
      "Epoch 115/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4995 - accuracy: 0.7769 - val_loss: 0.8391 - val_accuracy: 0.7377\n",
      "Epoch 116/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4577 - accuracy: 0.8264 - val_loss: 0.4617 - val_accuracy: 0.7705\n",
      "Epoch 117/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3938 - accuracy: 0.8223 - val_loss: 0.6296 - val_accuracy: 0.7377\n",
      "Epoch 118/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6969 - accuracy: 0.7438 - val_loss: 0.4887 - val_accuracy: 0.8197\n",
      "Epoch 119/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4771 - accuracy: 0.8306 - val_loss: 0.5072 - val_accuracy: 0.8033\n",
      "Epoch 120/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4866 - accuracy: 0.8058 - val_loss: 0.5649 - val_accuracy: 0.8033\n",
      "Epoch 121/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6234 - accuracy: 0.7727 - val_loss: 0.5641 - val_accuracy: 0.8033\n",
      "Epoch 122/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.7102 - accuracy: 0.7438 - val_loss: 0.4629 - val_accuracy: 0.8033\n",
      "Epoch 123/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5015 - accuracy: 0.8017 - val_loss: 1.2555 - val_accuracy: 0.4918\n",
      "Epoch 124/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5186 - accuracy: 0.7975 - val_loss: 0.6085 - val_accuracy: 0.7377\n",
      "Epoch 125/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.7494 - accuracy: 0.7273 - val_loss: 0.8146 - val_accuracy: 0.6066\n",
      "Epoch 126/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5561 - accuracy: 0.7810 - val_loss: 0.5136 - val_accuracy: 0.8033\n",
      "Epoch 127/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.7397 - accuracy: 0.7314 - val_loss: 0.6229 - val_accuracy: 0.8033\n",
      "Epoch 128/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4437 - accuracy: 0.8017 - val_loss: 0.4570 - val_accuracy: 0.8197\n",
      "Epoch 129/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4268 - accuracy: 0.8471 - val_loss: 0.4502 - val_accuracy: 0.8033\n",
      "Epoch 130/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4008 - accuracy: 0.8306 - val_loss: 0.4724 - val_accuracy: 0.8033\n",
      "Epoch 131/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3963 - accuracy: 0.8182 - val_loss: 0.5331 - val_accuracy: 0.8033\n",
      "Epoch 132/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4039 - accuracy: 0.8388 - val_loss: 0.5043 - val_accuracy: 0.8033\n",
      "Epoch 133/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3835 - accuracy: 0.8471 - val_loss: 0.4571 - val_accuracy: 0.8197\n",
      "Epoch 134/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4322 - accuracy: 0.8430 - val_loss: 1.0763 - val_accuracy: 0.5738\n",
      "Epoch 135/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5369 - accuracy: 0.7893 - val_loss: 0.4732 - val_accuracy: 0.7869\n",
      "Epoch 136/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4580 - accuracy: 0.7975 - val_loss: 0.4605 - val_accuracy: 0.8197\n",
      "Epoch 137/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4934 - accuracy: 0.7934 - val_loss: 0.4505 - val_accuracy: 0.8033\n",
      "Epoch 138/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4090 - accuracy: 0.7810 - val_loss: 0.6125 - val_accuracy: 0.7869\n",
      "Epoch 139/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5280 - accuracy: 0.7975 - val_loss: 0.5086 - val_accuracy: 0.8033\n",
      "Epoch 140/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3948 - accuracy: 0.8595 - val_loss: 0.4925 - val_accuracy: 0.8033\n",
      "Epoch 141/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3954 - accuracy: 0.8306 - val_loss: 0.5318 - val_accuracy: 0.8033\n",
      "Epoch 142/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4543 - accuracy: 0.8058 - val_loss: 0.4533 - val_accuracy: 0.8033\n",
      "Epoch 143/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4404 - accuracy: 0.8471 - val_loss: 0.5016 - val_accuracy: 0.8033\n",
      "Epoch 144/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4448 - accuracy: 0.7934 - val_loss: 0.4575 - val_accuracy: 0.8197\n",
      "Epoch 145/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3879 - accuracy: 0.8430 - val_loss: 0.4468 - val_accuracy: 0.8033\n",
      "Epoch 146/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4494 - accuracy: 0.8099 - val_loss: 0.4548 - val_accuracy: 0.7869\n",
      "Epoch 147/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4618 - accuracy: 0.8099 - val_loss: 0.5198 - val_accuracy: 0.8033\n",
      "Epoch 148/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4322 - accuracy: 0.8058 - val_loss: 0.4477 - val_accuracy: 0.8033\n",
      "Epoch 149/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4271 - accuracy: 0.7810 - val_loss: 0.4460 - val_accuracy: 0.8033\n",
      "Epoch 150/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3718 - accuracy: 0.8471 - val_loss: 0.7443 - val_accuracy: 0.7869\n",
      "Epoch 151/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5937 - accuracy: 0.7727 - val_loss: 0.4433 - val_accuracy: 0.7869\n",
      "Epoch 152/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4144 - accuracy: 0.8140 - val_loss: 0.4489 - val_accuracy: 0.8033\n",
      "Epoch 153/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4364 - accuracy: 0.8017 - val_loss: 0.5873 - val_accuracy: 0.7541\n",
      "Epoch 154/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3754 - accuracy: 0.8388 - val_loss: 0.4711 - val_accuracy: 0.8361\n",
      "Epoch 155/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5257 - accuracy: 0.7769 - val_loss: 0.5813 - val_accuracy: 0.7705\n",
      "Epoch 156/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4059 - accuracy: 0.8388 - val_loss: 0.5755 - val_accuracy: 0.7541\n",
      "Epoch 157/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4625 - accuracy: 0.8017 - val_loss: 0.7721 - val_accuracy: 0.6230\n",
      "Epoch 158/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5447 - accuracy: 0.7934 - val_loss: 0.4733 - val_accuracy: 0.8197\n",
      "Epoch 159/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4218 - accuracy: 0.8182 - val_loss: 0.6789 - val_accuracy: 0.7377\n",
      "Epoch 160/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.7399 - accuracy: 0.7025 - val_loss: 0.5010 - val_accuracy: 0.8033\n",
      "Epoch 161/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4581 - accuracy: 0.8099 - val_loss: 0.5528 - val_accuracy: 0.7705\n",
      "Epoch 162/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4759 - accuracy: 0.7975 - val_loss: 0.4769 - val_accuracy: 0.7869\n",
      "Epoch 163/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4638 - accuracy: 0.8058 - val_loss: 0.4862 - val_accuracy: 0.8197\n",
      "Epoch 164/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4019 - accuracy: 0.8388 - val_loss: 0.5634 - val_accuracy: 0.7705\n",
      "Epoch 165/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4269 - accuracy: 0.8306 - val_loss: 0.4654 - val_accuracy: 0.8361\n",
      "Epoch 166/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6313 - accuracy: 0.7686 - val_loss: 0.6093 - val_accuracy: 0.7541\n",
      "Epoch 167/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.7339 - accuracy: 0.7107 - val_loss: 0.4408 - val_accuracy: 0.8033\n",
      "Epoch 168/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.7810 - val_loss: 0.4772 - val_accuracy: 0.8197\n",
      "Epoch 169/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4058 - accuracy: 0.8264 - val_loss: 0.4836 - val_accuracy: 0.8033\n",
      "Epoch 170/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5360 - accuracy: 0.7727 - val_loss: 0.5266 - val_accuracy: 0.8197\n",
      "Epoch 171/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4853 - accuracy: 0.8223 - val_loss: 0.4448 - val_accuracy: 0.8033\n",
      "Epoch 172/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4061 - accuracy: 0.8347 - val_loss: 0.4533 - val_accuracy: 0.7869\n",
      "Epoch 173/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4168 - accuracy: 0.8223 - val_loss: 0.5250 - val_accuracy: 0.8033\n",
      "Epoch 174/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4106 - accuracy: 0.8264 - val_loss: 0.4677 - val_accuracy: 0.8033\n",
      "Epoch 175/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3749 - accuracy: 0.8264 - val_loss: 0.6493 - val_accuracy: 0.6885\n",
      "Epoch 176/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.8305 - accuracy: 0.6983 - val_loss: 1.3278 - val_accuracy: 0.4918\n",
      "Epoch 177/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5691 - accuracy: 0.7975 - val_loss: 0.8392 - val_accuracy: 0.5902\n",
      "Epoch 178/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5777 - accuracy: 0.7686 - val_loss: 0.6945 - val_accuracy: 0.6721\n",
      "Epoch 179/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4928 - accuracy: 0.7810 - val_loss: 0.5097 - val_accuracy: 0.8033\n",
      "Epoch 180/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5889 - accuracy: 0.7686 - val_loss: 0.4644 - val_accuracy: 0.8033\n",
      "Epoch 181/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.7789 - accuracy: 0.7149 - val_loss: 0.4394 - val_accuracy: 0.8033\n",
      "Epoch 182/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4494 - accuracy: 0.8223 - val_loss: 0.4428 - val_accuracy: 0.8197\n",
      "Epoch 183/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5012 - accuracy: 0.8017 - val_loss: 0.4406 - val_accuracy: 0.8033\n",
      "Epoch 184/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3816 - accuracy: 0.8430 - val_loss: 0.4891 - val_accuracy: 0.8033\n",
      "Epoch 185/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4060 - accuracy: 0.8264 - val_loss: 0.4581 - val_accuracy: 0.8197\n",
      "Epoch 186/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4735 - accuracy: 0.8058 - val_loss: 0.5767 - val_accuracy: 0.8033\n",
      "Epoch 187/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4788 - accuracy: 0.8182 - val_loss: 0.7751 - val_accuracy: 0.7705\n",
      "Epoch 188/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4955 - accuracy: 0.7893 - val_loss: 0.4475 - val_accuracy: 0.8197\n",
      "Epoch 189/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5690 - accuracy: 0.7769 - val_loss: 0.5562 - val_accuracy: 0.8033\n",
      "Epoch 190/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4340 - accuracy: 0.8182 - val_loss: 0.4487 - val_accuracy: 0.8033\n",
      "Epoch 191/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4041 - accuracy: 0.8182 - val_loss: 0.5620 - val_accuracy: 0.8033\n",
      "Epoch 192/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5476 - accuracy: 0.8058 - val_loss: 0.6874 - val_accuracy: 0.7705\n",
      "Epoch 193/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4900 - accuracy: 0.7975 - val_loss: 0.6398 - val_accuracy: 0.7213\n",
      "Epoch 194/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4160 - accuracy: 0.8182 - val_loss: 0.5654 - val_accuracy: 0.7705\n",
      "Epoch 195/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4674 - accuracy: 0.8017 - val_loss: 0.6147 - val_accuracy: 0.7213\n",
      "Epoch 196/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5811 - accuracy: 0.7769 - val_loss: 1.2455 - val_accuracy: 0.5082\n",
      "Epoch 197/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4847 - accuracy: 0.8017 - val_loss: 0.4975 - val_accuracy: 0.8033\n",
      "Epoch 198/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4525 - accuracy: 0.8017 - val_loss: 0.5155 - val_accuracy: 0.8361\n",
      "Epoch 199/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4610 - accuracy: 0.7975 - val_loss: 0.4383 - val_accuracy: 0.8197\n",
      "Epoch 200/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5650 - accuracy: 0.7727 - val_loss: 0.4281 - val_accuracy: 0.8033\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_train, epochs=200, batch_size=10,validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STEP 5 모델 결과 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate with test dataset : Loss = 0.4281\n",
      "Evaluate with test dataset : Accuracy = 0.8033\n"
     ]
    }
   ],
   "source": [
    "a,b = model.evaluate(x=X_test, y=Y_test, verbose=0) # 63개의 테스트 데이터셋 결과 \n",
    "print(\"Evaluate with test dataset : Loss = {:.4f}\".format(a))      # 테스트 데이터셋의 loss \n",
    "print(\"Evaluate with test dataset : Accuracy = {:.4f}\".format(b))  # 테스트 데이터셋의 accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STEP 6 그래프 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 데이터셋의 loss\n",
    "vloss1=history.history['val_loss']\n",
    "\n",
    "# 학습 데이터셋의 accuracy \n",
    "acc1=history.history['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'acc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-362f359bb192>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx_len\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0macc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m   \u001b[1;31m#그래프의 크기 셋팅\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mfont_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"C:\\\\Windows\\\\Fonts\\\\HMKMMAG.TTF\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mfont_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfont_manager\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFontProperties\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfont_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'font'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfamily\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfont_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m14\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'acc' is not defined"
     ]
    }
   ],
   "source": [
    "x_len = numpy.arange(len(acc))\n",
    "plt.figure(figsize=(8,6))   #그래프의 크기 셋팅\n",
    "font_path = \"C:\\\\Windows\\\\Fonts\\\\HMKMMAG.TTF\"\n",
    "font_name = matplotlib.font_manager.FontProperties(fname=font_path).get_name()\n",
    "plt.rc('font', family=font_name, size=14) \n",
    "\n",
    "# 학습 데이터셋의 accuracy는 파란색으로, 테스트 데이터셋의 loss는 빨간색으로 표시\n",
    "plt.title('테스트셋 오차와 학습셋의 정확도 비교', fontsize=14)\n",
    "plt.plot(x_len, vloss1, \"o\", c=\"red\",  markersize=3,  label='테스트 데이터셋 loss')\n",
    "plt.plot(x_len, acc1,   \"o\", c=\"blue\", markersize=3,  label='학습 데이터셋 accuracy')\n",
    "plt.legend() # 범례 출력\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2번째 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STEP 3 모델 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('heart_model2.h5') \n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 25)                350       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 15)                390       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 16        \n",
      "=================================================================\n",
      "Total params: 756\n",
      "Trainable params: 756\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STEP 4 모델 실행하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.6921 - accuracy: 0.5413 - val_loss: 0.6848 - val_accuracy: 0.5574\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6868 - accuracy: 0.5413 - val_loss: 0.6814 - val_accuracy: 0.5574\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6834 - accuracy: 0.5413 - val_loss: 0.6741 - val_accuracy: 0.5574\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6814 - accuracy: 0.5537 - val_loss: 0.6677 - val_accuracy: 0.7213\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6743 - accuracy: 0.5868 - val_loss: 0.6584 - val_accuracy: 0.5574\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6563 - accuracy: 0.6405 - val_loss: 0.6551 - val_accuracy: 0.5574\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6556 - accuracy: 0.5744 - val_loss: 0.6105 - val_accuracy: 0.7541\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6146 - accuracy: 0.7025 - val_loss: 0.5917 - val_accuracy: 0.6721\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6008 - accuracy: 0.6942 - val_loss: 0.5465 - val_accuracy: 0.7541\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5703 - accuracy: 0.6901 - val_loss: 0.5426 - val_accuracy: 0.7541\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.5741 - accuracy: 0.7066 - val_loss: 0.6242 - val_accuracy: 0.5902\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.5641 - accuracy: 0.7273 - val_loss: 0.4971 - val_accuracy: 0.8033\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5292 - accuracy: 0.7231 - val_loss: 0.4723 - val_accuracy: 0.8033\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5195 - accuracy: 0.7438 - val_loss: 0.4953 - val_accuracy: 0.7541\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.5388 - accuracy: 0.7025 - val_loss: 0.4864 - val_accuracy: 0.7541\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5191 - accuracy: 0.7479 - val_loss: 0.5995 - val_accuracy: 0.6721\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4870 - accuracy: 0.7603 - val_loss: 0.4739 - val_accuracy: 0.8033\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4976 - accuracy: 0.7521 - val_loss: 0.4473 - val_accuracy: 0.8197\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4756 - accuracy: 0.7521 - val_loss: 0.4290 - val_accuracy: 0.8033\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4746 - accuracy: 0.7727 - val_loss: 0.4194 - val_accuracy: 0.7869\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4636 - accuracy: 0.7934 - val_loss: 0.5024 - val_accuracy: 0.7869\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4708 - accuracy: 0.7851 - val_loss: 0.4093 - val_accuracy: 0.7869\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4454 - accuracy: 0.8017 - val_loss: 0.4135 - val_accuracy: 0.8197\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4414 - accuracy: 0.7934 - val_loss: 0.4041 - val_accuracy: 0.8197\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4353 - accuracy: 0.8017 - val_loss: 0.6876 - val_accuracy: 0.6066\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5515 - accuracy: 0.7397 - val_loss: 0.4381 - val_accuracy: 0.8033\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4729 - accuracy: 0.7727 - val_loss: 0.4060 - val_accuracy: 0.8197\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4377 - accuracy: 0.7975 - val_loss: 0.4010 - val_accuracy: 0.8033\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4553 - accuracy: 0.7893 - val_loss: 0.4186 - val_accuracy: 0.8033\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4380 - accuracy: 0.8017 - val_loss: 0.4024 - val_accuracy: 0.8033\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4250 - accuracy: 0.8017 - val_loss: 0.4111 - val_accuracy: 0.8033\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4229 - accuracy: 0.8099 - val_loss: 0.4316 - val_accuracy: 0.8033\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4720 - accuracy: 0.7727 - val_loss: 0.3976 - val_accuracy: 0.8197\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4118 - accuracy: 0.8182 - val_loss: 0.4005 - val_accuracy: 0.8197\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4202 - accuracy: 0.7934 - val_loss: 0.3973 - val_accuracy: 0.8197\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3986 - accuracy: 0.8182 - val_loss: 0.4669 - val_accuracy: 0.8033\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4252 - accuracy: 0.8388 - val_loss: 0.3872 - val_accuracy: 0.8361\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4125 - accuracy: 0.8182 - val_loss: 0.4637 - val_accuracy: 0.8033\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4185 - accuracy: 0.8058 - val_loss: 0.3868 - val_accuracy: 0.8197\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3965 - accuracy: 0.8264 - val_loss: 0.4349 - val_accuracy: 0.8033\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4805 - accuracy: 0.7603 - val_loss: 0.4740 - val_accuracy: 0.7869\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4305 - accuracy: 0.8017 - val_loss: 0.4112 - val_accuracy: 0.8361\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4047 - accuracy: 0.8264 - val_loss: 0.4061 - val_accuracy: 0.8361\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4097 - accuracy: 0.8140 - val_loss: 0.4273 - val_accuracy: 0.8033\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4082 - accuracy: 0.8306 - val_loss: 0.4100 - val_accuracy: 0.8197\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3958 - accuracy: 0.8264 - val_loss: 0.3943 - val_accuracy: 0.8361\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3939 - accuracy: 0.8471 - val_loss: 0.3927 - val_accuracy: 0.8361\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3811 - accuracy: 0.8430 - val_loss: 0.3854 - val_accuracy: 0.8033\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3753 - accuracy: 0.8347 - val_loss: 0.4927 - val_accuracy: 0.8033\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.8223 - val_loss: 0.3932 - val_accuracy: 0.8197\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4012 - accuracy: 0.8306 - val_loss: 0.4349 - val_accuracy: 0.8197\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4713 - accuracy: 0.7851 - val_loss: 0.4957 - val_accuracy: 0.7705\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4149 - accuracy: 0.8140 - val_loss: 0.4233 - val_accuracy: 0.8361\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3770 - accuracy: 0.8347 - val_loss: 0.4020 - val_accuracy: 0.8197\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3764 - accuracy: 0.8388 - val_loss: 0.3942 - val_accuracy: 0.8361\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4102 - accuracy: 0.8099 - val_loss: 0.4044 - val_accuracy: 0.8197\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3858 - accuracy: 0.8264 - val_loss: 0.3902 - val_accuracy: 0.8197\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3919 - accuracy: 0.8430 - val_loss: 0.3899 - val_accuracy: 0.8197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3813 - accuracy: 0.8388 - val_loss: 0.3937 - val_accuracy: 0.8197\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3637 - accuracy: 0.8388 - val_loss: 0.4627 - val_accuracy: 0.8033\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4017 - accuracy: 0.8223 - val_loss: 0.3974 - val_accuracy: 0.8361\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3953 - accuracy: 0.8264 - val_loss: 0.4412 - val_accuracy: 0.8197\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3993 - accuracy: 0.8306 - val_loss: 0.4322 - val_accuracy: 0.8361\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3764 - accuracy: 0.8471 - val_loss: 0.4101 - val_accuracy: 0.8525\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3735 - accuracy: 0.8388 - val_loss: 0.3992 - val_accuracy: 0.8361\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3945 - accuracy: 0.7975 - val_loss: 0.3978 - val_accuracy: 0.8197\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3865 - accuracy: 0.8182 - val_loss: 0.4417 - val_accuracy: 0.8361\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4405 - accuracy: 0.7727 - val_loss: 0.4004 - val_accuracy: 0.8197\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4453 - accuracy: 0.7893 - val_loss: 0.4069 - val_accuracy: 0.8197\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3825 - accuracy: 0.8306 - val_loss: 0.3945 - val_accuracy: 0.8197\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3746 - accuracy: 0.8264 - val_loss: 0.3959 - val_accuracy: 0.8197\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3783 - accuracy: 0.8388 - val_loss: 0.4041 - val_accuracy: 0.8197\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4175 - accuracy: 0.8017 - val_loss: 0.4783 - val_accuracy: 0.7705\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3910 - accuracy: 0.8306 - val_loss: 0.4040 - val_accuracy: 0.8361\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3899 - accuracy: 0.8182 - val_loss: 0.4571 - val_accuracy: 0.8197\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3723 - accuracy: 0.8223 - val_loss: 0.5244 - val_accuracy: 0.7705\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4164 - accuracy: 0.8017 - val_loss: 0.5647 - val_accuracy: 0.7213\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4667 - accuracy: 0.7975 - val_loss: 0.4645 - val_accuracy: 0.8033\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3906 - accuracy: 0.8347 - val_loss: 0.4351 - val_accuracy: 0.8525\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3837 - accuracy: 0.8471 - val_loss: 0.3959 - val_accuracy: 0.8197\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3661 - accuracy: 0.8512 - val_loss: 0.4136 - val_accuracy: 0.8033\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3981 - accuracy: 0.8264 - val_loss: 0.4122 - val_accuracy: 0.8033\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4053 - accuracy: 0.8140 - val_loss: 0.4538 - val_accuracy: 0.8197\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4123 - accuracy: 0.8264 - val_loss: 0.3965 - val_accuracy: 0.8197\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3634 - accuracy: 0.8471 - val_loss: 0.4606 - val_accuracy: 0.8197\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4044 - accuracy: 0.8099 - val_loss: 0.5147 - val_accuracy: 0.7869\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3989 - accuracy: 0.8347 - val_loss: 0.3934 - val_accuracy: 0.8197\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3778 - accuracy: 0.8388 - val_loss: 0.4038 - val_accuracy: 0.8197\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3681 - accuracy: 0.8347 - val_loss: 0.4156 - val_accuracy: 0.8197\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3892 - accuracy: 0.8182 - val_loss: 0.3908 - val_accuracy: 0.8197\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3850 - accuracy: 0.8388 - val_loss: 0.4153 - val_accuracy: 0.8197\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3700 - accuracy: 0.8471 - val_loss: 0.4002 - val_accuracy: 0.8361\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3883 - accuracy: 0.8388 - val_loss: 0.3939 - val_accuracy: 0.8197\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3788 - accuracy: 0.8223 - val_loss: 0.4365 - val_accuracy: 0.8197\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3740 - accuracy: 0.8182 - val_loss: 0.3913 - val_accuracy: 0.8197\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3601 - accuracy: 0.8678 - val_loss: 0.4261 - val_accuracy: 0.8197\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3944 - accuracy: 0.8223 - val_loss: 0.3877 - val_accuracy: 0.8197\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3751 - accuracy: 0.8471 - val_loss: 0.4183 - val_accuracy: 0.8525\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3886 - accuracy: 0.8264 - val_loss: 0.4412 - val_accuracy: 0.8361\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3778 - accuracy: 0.8512 - val_loss: 0.3946 - val_accuracy: 0.8361\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3676 - accuracy: 0.8471 - val_loss: 0.3967 - val_accuracy: 0.8197\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3789 - accuracy: 0.8182 - val_loss: 0.3956 - val_accuracy: 0.8361\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3634 - accuracy: 0.8512 - val_loss: 0.4154 - val_accuracy: 0.8525\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3710 - accuracy: 0.8388 - val_loss: 0.3941 - val_accuracy: 0.8197\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3715 - accuracy: 0.8306 - val_loss: 0.3993 - val_accuracy: 0.8361\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3655 - accuracy: 0.8554 - val_loss: 0.3961 - val_accuracy: 0.8361\n",
      "Epoch 107/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4259 - accuracy: 0.8017 - val_loss: 0.4468 - val_accuracy: 0.8361\n",
      "Epoch 108/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3679 - accuracy: 0.8430 - val_loss: 0.3994 - val_accuracy: 0.8197\n",
      "Epoch 109/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3757 - accuracy: 0.8512 - val_loss: 0.3938 - val_accuracy: 0.8197\n",
      "Epoch 110/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4088 - accuracy: 0.8264 - val_loss: 0.4083 - val_accuracy: 0.8525\n",
      "Epoch 111/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3613 - accuracy: 0.8223 - val_loss: 0.4396 - val_accuracy: 0.8525\n",
      "Epoch 112/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3807 - accuracy: 0.8182 - val_loss: 0.4060 - val_accuracy: 0.8525\n",
      "Epoch 113/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4050 - accuracy: 0.8306 - val_loss: 0.3962 - val_accuracy: 0.8197\n",
      "Epoch 114/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3790 - accuracy: 0.8595 - val_loss: 0.4177 - val_accuracy: 0.8197\n",
      "Epoch 115/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3761 - accuracy: 0.8223 - val_loss: 0.4515 - val_accuracy: 0.8197\n",
      "Epoch 116/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3728 - accuracy: 0.8264 - val_loss: 0.3981 - val_accuracy: 0.8197\n",
      "Epoch 117/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3857 - accuracy: 0.8058 - val_loss: 0.3947 - val_accuracy: 0.8361\n",
      "Epoch 118/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4012 - accuracy: 0.8182 - val_loss: 0.3914 - val_accuracy: 0.8361\n",
      "Epoch 119/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3611 - accuracy: 0.8306 - val_loss: 0.4317 - val_accuracy: 0.8525\n",
      "Epoch 120/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3735 - accuracy: 0.8388 - val_loss: 0.4014 - val_accuracy: 0.8361\n",
      "Epoch 121/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4553 - accuracy: 0.7810 - val_loss: 0.4046 - val_accuracy: 0.8525\n",
      "Epoch 122/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3752 - accuracy: 0.8430 - val_loss: 0.3994 - val_accuracy: 0.8361\n",
      "Epoch 123/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3759 - accuracy: 0.8512 - val_loss: 0.4136 - val_accuracy: 0.8361\n",
      "Epoch 124/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3719 - accuracy: 0.8347 - val_loss: 0.4015 - val_accuracy: 0.8361\n",
      "Epoch 125/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3666 - accuracy: 0.8388 - val_loss: 0.4409 - val_accuracy: 0.8525\n",
      "Epoch 126/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3745 - accuracy: 0.8471 - val_loss: 0.3955 - val_accuracy: 0.8361\n",
      "Epoch 127/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3841 - accuracy: 0.8471 - val_loss: 0.4226 - val_accuracy: 0.8033\n",
      "Epoch 128/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4116 - accuracy: 0.7893 - val_loss: 0.4005 - val_accuracy: 0.8033\n",
      "Epoch 129/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3689 - accuracy: 0.8430 - val_loss: 0.3930 - val_accuracy: 0.8361\n",
      "Epoch 130/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3659 - accuracy: 0.8471 - val_loss: 0.4401 - val_accuracy: 0.8197\n",
      "Epoch 131/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3718 - accuracy: 0.8347 - val_loss: 0.4071 - val_accuracy: 0.8361\n",
      "Epoch 132/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3594 - accuracy: 0.8554 - val_loss: 0.3970 - val_accuracy: 0.8197\n",
      "Epoch 133/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3555 - accuracy: 0.8554 - val_loss: 0.4734 - val_accuracy: 0.7869\n",
      "Epoch 134/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3821 - accuracy: 0.8264 - val_loss: 0.4756 - val_accuracy: 0.7705\n",
      "Epoch 135/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3816 - accuracy: 0.8306 - val_loss: 0.3929 - val_accuracy: 0.8361\n",
      "Epoch 136/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3616 - accuracy: 0.8595 - val_loss: 0.3921 - val_accuracy: 0.8361\n",
      "Epoch 137/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3619 - accuracy: 0.8471 - val_loss: 0.4026 - val_accuracy: 0.8197\n",
      "Epoch 138/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3742 - accuracy: 0.8388 - val_loss: 0.3978 - val_accuracy: 0.8525\n",
      "Epoch 139/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3608 - accuracy: 0.8264 - val_loss: 0.3996 - val_accuracy: 0.8361\n",
      "Epoch 140/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3692 - accuracy: 0.8306 - val_loss: 0.4030 - val_accuracy: 0.8197\n",
      "Epoch 141/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3964 - accuracy: 0.8017 - val_loss: 0.4335 - val_accuracy: 0.8525\n",
      "Epoch 142/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3898 - accuracy: 0.8388 - val_loss: 0.3989 - val_accuracy: 0.8361\n",
      "Epoch 143/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3658 - accuracy: 0.8554 - val_loss: 0.3927 - val_accuracy: 0.8197\n",
      "Epoch 144/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3675 - accuracy: 0.8347 - val_loss: 0.4479 - val_accuracy: 0.8033\n",
      "Epoch 145/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3694 - accuracy: 0.8264 - val_loss: 0.3988 - val_accuracy: 0.8197\n",
      "Epoch 146/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3738 - accuracy: 0.8306 - val_loss: 0.4149 - val_accuracy: 0.8197\n",
      "Epoch 147/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3934 - accuracy: 0.8306 - val_loss: 0.3936 - val_accuracy: 0.8361\n",
      "Epoch 148/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3716 - accuracy: 0.8388 - val_loss: 0.3928 - val_accuracy: 0.8361\n",
      "Epoch 149/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3729 - accuracy: 0.8140 - val_loss: 0.3953 - val_accuracy: 0.8197\n",
      "Epoch 150/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3627 - accuracy: 0.8430 - val_loss: 0.3976 - val_accuracy: 0.8197\n",
      "Epoch 151/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3613 - accuracy: 0.8388 - val_loss: 0.3937 - val_accuracy: 0.8361\n",
      "Epoch 152/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3638 - accuracy: 0.8430 - val_loss: 0.3926 - val_accuracy: 0.8361\n",
      "Epoch 153/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3641 - accuracy: 0.8471 - val_loss: 0.3938 - val_accuracy: 0.8197\n",
      "Epoch 154/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3713 - accuracy: 0.8388 - val_loss: 0.4183 - val_accuracy: 0.8525\n",
      "Epoch 155/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3794 - accuracy: 0.8264 - val_loss: 0.4584 - val_accuracy: 0.8197\n",
      "Epoch 156/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3907 - accuracy: 0.8306 - val_loss: 0.4359 - val_accuracy: 0.8197\n",
      "Epoch 157/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3707 - accuracy: 0.8388 - val_loss: 0.3914 - val_accuracy: 0.8361\n",
      "Epoch 158/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3761 - accuracy: 0.8430 - val_loss: 0.3892 - val_accuracy: 0.8361\n",
      "Epoch 159/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3487 - accuracy: 0.8306 - val_loss: 0.4428 - val_accuracy: 0.8197\n",
      "Epoch 160/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3917 - accuracy: 0.8347 - val_loss: 0.3959 - val_accuracy: 0.8361\n",
      "Epoch 161/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3544 - accuracy: 0.8554 - val_loss: 0.4134 - val_accuracy: 0.8525\n",
      "Epoch 162/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3588 - accuracy: 0.8388 - val_loss: 0.4081 - val_accuracy: 0.8197\n",
      "Epoch 163/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3763 - accuracy: 0.8264 - val_loss: 0.4313 - val_accuracy: 0.8197\n",
      "Epoch 164/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3715 - accuracy: 0.8306 - val_loss: 0.4172 - val_accuracy: 0.8197\n",
      "Epoch 165/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3824 - accuracy: 0.8140 - val_loss: 0.4143 - val_accuracy: 0.8525\n",
      "Epoch 166/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3732 - accuracy: 0.8512 - val_loss: 0.3958 - val_accuracy: 0.8197\n",
      "Epoch 167/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3874 - accuracy: 0.8182 - val_loss: 0.3998 - val_accuracy: 0.8197\n",
      "Epoch 168/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3636 - accuracy: 0.8554 - val_loss: 0.3967 - val_accuracy: 0.8197\n",
      "Epoch 169/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3589 - accuracy: 0.8388 - val_loss: 0.4065 - val_accuracy: 0.8361\n",
      "Epoch 170/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3889 - accuracy: 0.8223 - val_loss: 0.5081 - val_accuracy: 0.7705\n",
      "Epoch 171/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4017 - accuracy: 0.8099 - val_loss: 0.4279 - val_accuracy: 0.8361\n",
      "Epoch 172/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3559 - accuracy: 0.8388 - val_loss: 0.4019 - val_accuracy: 0.8525\n",
      "Epoch 173/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3601 - accuracy: 0.8554 - val_loss: 0.4111 - val_accuracy: 0.8361\n",
      "Epoch 174/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3683 - accuracy: 0.8388 - val_loss: 0.4282 - val_accuracy: 0.8525\n",
      "Epoch 175/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4045 - accuracy: 0.8347 - val_loss: 0.3989 - val_accuracy: 0.8525\n",
      "Epoch 176/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3641 - accuracy: 0.8430 - val_loss: 0.3944 - val_accuracy: 0.8361\n",
      "Epoch 177/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3637 - accuracy: 0.8388 - val_loss: 0.3933 - val_accuracy: 0.8197\n",
      "Epoch 178/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3615 - accuracy: 0.8595 - val_loss: 0.4064 - val_accuracy: 0.8197\n",
      "Epoch 179/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3549 - accuracy: 0.8678 - val_loss: 0.4728 - val_accuracy: 0.7869\n",
      "Epoch 180/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3971 - accuracy: 0.8223 - val_loss: 0.3983 - val_accuracy: 0.8525\n",
      "Epoch 181/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3744 - accuracy: 0.8388 - val_loss: 0.3905 - val_accuracy: 0.8197\n",
      "Epoch 182/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3524 - accuracy: 0.8554 - val_loss: 0.3902 - val_accuracy: 0.8361\n",
      "Epoch 183/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3517 - accuracy: 0.8512 - val_loss: 0.4142 - val_accuracy: 0.8197\n",
      "Epoch 184/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3724 - accuracy: 0.8223 - val_loss: 0.4099 - val_accuracy: 0.8197\n",
      "Epoch 185/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3509 - accuracy: 0.8471 - val_loss: 0.4002 - val_accuracy: 0.8197\n",
      "Epoch 186/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4056 - accuracy: 0.7975 - val_loss: 0.3954 - val_accuracy: 0.8197\n",
      "Epoch 187/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3649 - accuracy: 0.8347 - val_loss: 0.4124 - val_accuracy: 0.8033\n",
      "Epoch 188/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3543 - accuracy: 0.8471 - val_loss: 0.3976 - val_accuracy: 0.8197\n",
      "Epoch 189/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3536 - accuracy: 0.8636 - val_loss: 0.3971 - val_accuracy: 0.8361\n",
      "Epoch 190/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3676 - accuracy: 0.8347 - val_loss: 0.4171 - val_accuracy: 0.8033\n",
      "Epoch 191/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3857 - accuracy: 0.8264 - val_loss: 0.4462 - val_accuracy: 0.8361\n",
      "Epoch 192/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3801 - accuracy: 0.8182 - val_loss: 0.4691 - val_accuracy: 0.8033\n",
      "Epoch 193/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3685 - accuracy: 0.8140 - val_loss: 0.3983 - val_accuracy: 0.8525\n",
      "Epoch 194/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3868 - accuracy: 0.8140 - val_loss: 0.4559 - val_accuracy: 0.8197\n",
      "Epoch 195/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3944 - accuracy: 0.8058 - val_loss: 0.3980 - val_accuracy: 0.8361\n",
      "Epoch 196/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3559 - accuracy: 0.8512 - val_loss: 0.4384 - val_accuracy: 0.8361\n",
      "Epoch 197/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3616 - accuracy: 0.8347 - val_loss: 0.3956 - val_accuracy: 0.8525\n",
      "Epoch 198/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3502 - accuracy: 0.8388 - val_loss: 0.4017 - val_accuracy: 0.8197\n",
      "Epoch 199/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3579 - accuracy: 0.8554 - val_loss: 0.4059 - val_accuracy: 0.8197\n",
      "Epoch 200/200\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3480 - accuracy: 0.8512 - val_loss: 0.3990 - val_accuracy: 0.8197\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_train, epochs=200, batch_size=10,validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 데이터셋의 loss\n",
    "vloss=history.history['val_loss']\n",
    "\n",
    "# 학습 데이터셋의 accuracy \n",
    "acc=history.history['accuracy']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STEP 5 모델 결과 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate with test dataset : Loss = 0.3990\n",
      "Evaluate with test dataset : Accuracy = 0.8197\n"
     ]
    }
   ],
   "source": [
    "a,b = model.evaluate(x=X_test, y=Y_test, verbose=0) # 63개의 테스트 데이터셋 결과 \n",
    "print(\"Evaluate with test dataset : Loss = {:.4f}\".format(a))      # 테스트 데이터셋의 loss \n",
    "print(\"Evaluate with test dataset : Accuracy = {:.4f}\".format(b))  # 테스트 데이터셋의 accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STEP 6 그래프 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeYAAAF4CAYAAACB/1r8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd7gU5dnH8e9zDsUDgjTBCGLDAgKKgnJieRXFaIwmiiYvxkQvK9FoNIn6WqIUgZhq1JhYYo3GGI2JJppE0UQiaAQCYkcs2BA59F7O/f4xs4c9y5bZ3Znd2d3f57r22nN2Z2eeZ9r9tJlxZoaIiIjEQ125EyAiIiJbKDCLiIjEiAKziIhIjCgwi4iIxIgCs4iISIwoMEvJOed2cc59yTl3oHNuV+dcx5TvujnnGjL8tpNz7h7n3KEZvt/OOfcz59z/OefOdM4d75w7yDm31b7unDvDObdD0v/OObeHc65jpuVnyVN351znLN+3cc7Ndc5dnfRZvb+8tL/LNc8AaerlnNvWOTfGOfe6c27vlHnv7Jxrk+G3dc65251zX8oy/32dc19wzrmUZfZxzm2TvM6dcw3Ouaucc4855251zg3IMy9dnHN9/e2bbltOds593f97ez9/w5xz7znnvhFwGT39PPV1zm2bR9p6OudOd87t7v/fyzm3p3OurXOut3Oud8r0/Z1zBzjnPuecqw+6HKkhZqaXXiV9AWMAA6YA/wBeAu72v3sVeAR4Gfhjmt9e5f/26gzz3tv//jHgCuBHwO2AS5nuUH+6J5M+297/7Fr//aIAedkLeNGf3oAngV5J3x8O/Ba4z/9+KvAd4Higj//Z9fnMM4/1PCVpHgZ8ArwOnAdc7X/WP8Nvv+5/f3uA+R+U9NkvgSbgRmCJ/1k98AKwGLgN+A+wFhgCOKAuQF5OAp4HFgHN/rwWAMf5328Efuf/fY3/fyLfy4H52fLi/+5b/vTP+a+XgXsDpO0I/3dn+f9f7v8/CPgLsDxl+q/6+8Oz/vaY56+TI8p9bOoVj5dqzFIO3fz3C83saDMbBlzm14R6AEuBrsCy5B/5tcfv4p1ob8wx7znAb4D/M7NzzCz1gv3x/vs4v3bXxV92smVk4dd2HvWn+xzQD+gF3JM02SzgeqCv///TwBK84NLV/2xp0Hk65y5xzp2fLV1JPvJfxwBDgbfw1s+96ZadkoYfAJuA6zLk/TBgBPA3M3vRr6G2Jf32OwE4EPgfMzsXGA78F68AtB+wyTl3UbaMmNkf/eWtANYBBwC7AE8657YB2iQt7wO8gD8GLzje7097m3Pu6865ZxO12xSJfefbZnaYmQ02s29mS1fK7xqdcycDg/3/E+uh1To2s4fM7BtmdoSZ9QcmAMPwCisipG3GEolY4kT2B+fcBmANMBB4F+hJhhMacJH/21XAD5xzV5jZpgzzPgr4PNDNOXe/mf0kMYFz7nC8muxmf7mbgZ/hBcJkWwWtFHsD/YHTzGyhP++xwJ+cc53MbKWZrXDOrQMO9n+zwMzu86c9zP/sVOfcrsC/8AoUGeeJV6tbAtySI20AXwQmmdnf/flcBMz2050IzL92zr0P/MrM3vA/G41Xa1+NV3A538zWpMw7UbDp4pzbEbgSaAT2BN6g9fbbHWgys1cBzKzZOfcv4Ev+dM5fVi7f9ef1ZiLtwE54NXLYEpi/iFdguNXP97eB/wUOAbrgbft0uvvviwOkJVlin1uFtz/tl5SedPtxqn3897fyXK5UKdWYpRwSJ7L98WpyJwE74J3YwTvBdaR1TTJRW16CF1j6As+m9t8lzXusmR1pZkOSg7JvnP8+GjgHuBD4gv+eLNcJdZ3/vkPSZ5/DC/Qbkj67Gi94XAp82zn3G78PuyU4AnfhBZxc8+yKV8Psk6l/OMlaWhc2dvTfl/vzWQNcBvwZb70m15Y34DU1rwReTOmfHgH8D/AE8Du8ZvdHzewA4DW2Lli9BvRwzn3e//02wLH+5xlr7smSgv/7fvr+gVfI+CLefgFbAvNGYLuknzcA7fH2qy7+Z/2cczsk94+zZd9pypaWNBK/u9PMxuIVTDaZ2SqCBeYBwGIzW5LncqVKqcYs5dAN78R/GF4tJfH6Tcp0ySe0M/BOcleZ2UfA15xzF+DViv+QNF2i1nOyc+6YpHmP95tcj/SX+1cz+4Nz7s/AT/D6rl/Jsvx03sHri7zVOfdDoC1e8+xvzWw9gHOuH15/7avAT4GbgBv813R/Pm+Z2Qv+9C7bPP0m917AzUBnvObdTG4FrvED4WLgAuBpM3vHOdcVWGpmb9G6pnYcXq33VjObB1zonPuqv5xEjTpRsBlrZi85514EfuO3AHQB3sPrP//Yn+5J//WUc24KXiDqhtfXmmg1yLWurwa2Bc4ws0ecc08BPwb29T+HLYH5t8BfnXO/Av6Nt++sxytIJMYWnO6ncSzwjP+7bniFlT7Oue3xxhxsD/zLzOZnSVsiMB/uF1r2S8pP2sDsnNsN+NRf3j6otixJFJilHN7DG5x1It5gnkV4taft8Po1E1pOaGZ2o3NuLjAj6bNfppn3HLxa4CLgs6T5f+J//1+8Gtaz/jw2ABf5/dtn4p20t1p+OmZmzrlReIH9Zv/jG/CCfMIKvH7aGX4/93rgW8659sDZ/vKWBZmn35TdBvi7mX07W9p8k/x1cCrQAbjTny94tcit+tDN7DHn3DC2BFXM7KGUya4ChpvZS/73LzrnBvtN1A2k1Jj9PB0PfBOvr3kGcIeZfeyc+7I/z1yB+SLg92b2L3+ey4Bz/BaTy/1pVvnfPeGcOxV4AK+fGWComX3kF2xWmNmpaZaxDq8A9bb//2S8fSfXAwXeA+7A61//GG//et8vELnUvPlpmI9XKNgA7Io3+EsE8EeqisSFX2Nsg3eSW2Fmq/3PhwAT8WqJnf1pDFhrZkOTfv99vGbpzng1KedP9zszSzuQyf9dG7zCwnPAz/H6uj8ys+YAaa4D/oo3qOkIvALGm4k+4gC/tdTBaRnmuQ5vdPMkM7sqdV5BOOcewhsQ5fAKQQvxauN3+9/3xqtpJ9ZzO/+nBhxiZhkDqHPuNLx+48nAh3gZa3LOdcMrFCTm2YEtwe4/eDXaXczs/TzzchDwFNDJ/+g5YISZbfa//wbeQLdz8QLuGrwWi75mtnOGedbjFdr2xBs0tx3wupktyidtKfNskzwWwjm3D17rzHV4feSnAycDL/itQVLjFJilIjjnOuA14S7HC9ipg74S0+2AF7SXA6vSjMbONP8z8ZrSf2FmF+eRrmfw+rtX+MtMvH6VaJ7OV5Z5/gmv0PFXM3u8kHmnLGcQ3iVBY81snP9ZW2APvJricjPbGHBebfCaYz8H7GZmnyR9V+/Pc7k/zzVJ33XG60+fnwioeaT/73jNwBfjjYT+AXAKXl/6JXg16MS6G4TXrL0C2GBmW40C95vku7FlvSfebzKzGanTF8o59xJei0UibYnl3Gpms8JajlQuBWapeUlBZUe8wUXnmNlz5U1V9Jxzw/H6ub9jZjcmff4x8KqZjfT//xvwnpmNST8ncM6dhdecuxK4G+8ytdSR3KHyuzaeNLPL/P8/AyYk5yVp2ivxasHb49VS9wQuNbObokyjSCE0KlvEa0rcFe/mGKcCN/uXKFW7Dnh9nKmjgbsCBzrnZjvn/oM38KtPppn4BZur8EaB74MXnGf6A9+i9C/gOOfdres0P91pC1RmNsnMzjCz44Dz8UZpB2oNECk1Df4S8U7w44Ffm9kn/uCnfXL8puKZ2TNAe9f61pnbANsA95nZuf7/a8k+OMvhDcDqYmYf4A1UewTvRh9Rugqvlv4fvIFs55nZ7AC/S1wylfUGMiLloqZsEWnhnPsc3sjixIh2hxfIbjWz8dl+Wy7Oufp8+qedd5/1a4BrzWxadCkTKYwCs4i08JulewArEyPiRaS0FJhFRERiRIO/REREYkSBWUREJEYUmEVERGIkFpdL9ejRw3bZZZdyJ0NERKRkZs6cudjMtk/9PBaBeZdddmHGjNDueCciIhJ7/rPQt6KmbBERkRhRYBYREYkRBWYREZEYUWAWERGJEQVmERGRGFFgFhERiREFZhERkRhRYBYREYkRBWYREZEYUWAWERGJEQVmERGRGFFgFqlC06fD5Mneu0hcaT9NLxYPsRCR8EyfDkceCRs2QLt2MGUKNDaWO1UirWk/zUw1ZpEq889/eie7zZu993/+s9wpEtma9tPMFJhFqszhh3s1kPp67/3ww8udIpGtRbGfVkvTuJqyRapMY6PXLPjPf3onOzUPShyFvZ9WU9O4ArNIFWpsjN9Jafr0yissVGKaK0Hyer3iinDmma5pvFK3mQKziESuEmszlZjmShDVek00jSfmW8ldOOpjFpHIVeJAn0pMcyWIar0mmsYnTKj8QpRqzCISSDHNunGtzSTy1L07NDW1zlsxaY5jE3ihaQr6u6DTBVmvhaY17C6csm1HMyv764ADDjARia9p08waGszq6733adMKm8ekSYX9NgqJPNXVmYH3npq3QtIcxroKW6FpCvq7fOefbb3GZf2VIh3ADEsTE9WULRKhOF++kSlt6T7P1vwYNI+Njd5AnzBG34axThN5am72/m9u3jpvhaQ5jk3g+aQpef0G/V2+ec62XpPntX49jB0b/fGTa58vVTpapIvWpX6pxizVKC4l/3QypS2sz0ud7mLmla3GXO40hqXQmu+tt0ZTYw6S1rC3S67lZdq3o0wHqjGLlFYca04JmdKW6fNMA2tKnccwl5fI03XXwa23eu9hDBqK4yCkoGlKXb9NTcF+F2aeE/M66iioq0vfkhGmXPt8qdKRTIO/JBRxGuwSh7RMnw4LFkAb/wgLe5BLvr9LnT55AE59vZfW6dOzD8xJN7Cm1IO6ci0v22Cu5O8TnwcdLJTv+o7iOvJi9+sgaUq3foPmJcw8NzZ6TcdTp7ZOS6Z1ENXAxEzpiFy6anSpX2rKrmxxarqLQ1qS09CundmYMeEOcilkoE2mproxY8zat2/9Xb4Dnko9qCvT8nI1PZZqfUehlGmI0yC95LRE2Z2SK89RrRPUlC1RiXqQRD6DfeLQfJychs2boW/f3INc8klrvr/L1lTXty9s2rT13ZKCDHhKbBcIZ1BXLrmWl20w1/Tp3n65fn3067sY6fb1fNNe7OC4sAbphZGe5LTk2/1S6HIK+T506aJ1qV+qMVe2KAdJhFU7LKWoLjEp9HfZpq+UWmSQ5WXaDxMDmArdP0uV13TLyffYisP+H1V64jIAMUxkqDGrj1mKlhgkMXYsPP1065pKsSXMfO9/G4cHOARNQ6Fpzfd32aYvNA2lvi9xkOUl5yW5jzm5Jl1X5w3mGTs2uvVdqEw1v3zSHrf7RYeZnkzbIQ7HfNicF7TLa+jQoTZjxoxyJ6OmRDFAqth74KZLU/I86+vhzDNhyJD0A3uCzK/QdJRa0EEuUaY127xLcR/p5OVD5uXlWgdhpjXIsgodlAet03nDDfDf/8Jdd3ndDYm0Q+Z94957t54+3bYL87jItk+my1O2YzcOx14p0+Gcm2lmQ7f6Il01utQvNWWXVpRNP4UOksjV3JoYpBR1k14cmsWCNtkFvcY0zDSkThPVIKFMzbqpy8un26DYtOZaVhhdDIl0Jm/b5AGEQfaNUg44DLJPpstTGOsvKqVMBxr8JQlRDmZJHiQRdNBHrsEtyYOUst2lKVmpBlaly0sxA29S10XyYLrUtD3ySHTbMch6iHJATKYm0OTl5TMoKt1v891OudZJuu+zLSdbHpua0g8gDDIAKnXAYSF38gqa92z7ZGLfha3zFHT95ZLP3euCKGaQYKjSRetSv1RjLq1SlAjzHQCVqyZcqkEwxaybYtdrah6dSz+IKS415igFrZ0WMqArqn0j3xaNQgblFft5oftMvvNPt11K0eJQyHxS51eqO46ZafCXJCnFYImggz6CDszJNLCn3AOr0uWl0IEuqetit93gnXe2tA4k7sKUnLZBg6LZjuUeUJNr+cUM6Cp0O+VKU+r3uZZTyKC8fD9PTUO6fSiIfJY7aFD6gaBXXJHf+suVtkzrt9DtW+wgwVCli9alfqnGXHly9dmF3UcYRpqKyUuQ+YZVYy5FjTjfdBXTP5vv74NMH3XLRj7bPJ+nJCX3t4bVP58pDdOmpb+BTD55KCZN5WqVK0drWaHIUGMue1A2BeaKk08zda679qROF3Wa8v1dIc1rYQaxKE6a+aYnzMJGmIWbYtZNvgG10LSmOwbCbCoNEpyiGAwWNG1R77vZCiVRFNLDpsAsgQTZ0SdN8g7kxMnl6KNz78jJv6mv9/4vNC3ppjv66C0nvKDzT01XurwUku4geSlXwM13ufnkP928s/0+3+lLIei+lO8+lzp94lXsPpUpDUHWYzHHTaUod8E2FwVmySlo01Ahd1KKquZUbC0k1+/DqFHEpYm6kLwUW3sM6/NSCLov5bvPpU6fOqivmH2q0P02itp73JRzXwoqU2DW5VLSIuglEYkBJPk8Di0xsCPoY+GCXjqRbsBGPjeQSKQrU17yTXeQvER5mVM+6Qiy3KD5zzTvTL/Pd/pSCLov5bvPpU4/cmTxj5nMlYZc67HY46YSRHlZaOTSRetSv1RjjoeoajeFNCcF7b8LMrglrOWlTh80T6WoMQfpgoi6PzFIn2Zi2rC2W5jC7FsuZvow0xrF76NoHs41z6jOIeWGmrIliHwHUwQ5oKI4AeQTCMJYXqZl59MkHFUfcz4Fpyj73IIE3Ci2W5jy2QfK/WjMYucZl2AXtNk9LoWIMCkw16hcASHqHTeqwTxRDibLNY9yDJjJlvZMA9jyXUdhrJ9iBtPF/SRaa9JtjyiO51zzDGOZcd23FJhrUK4m1FIMQoqqOakczYnlGjATtEaR6XGHQS89CmM75VpH+dTupXxKuZ2irDFHleawZArMGvxVxXINOirFIKSoBvNENZgsyDxKPWAmV9ozDWBLDNILso7CGihT6GC6ih6oU4VKOTgv1zyLXWZF7lvponWpX6oxRyOKGnPYfaOlal4Ks8Zc7Dyi6tcrti8uzFpFOVo0KlkcmlqT01BN2yPduIYw77xWDDLUmPU85iqX6/m9+Tx3NOzn2kb9PN90yyz23s/FzKOYPAddbrHpC/Pe2MU8m7iaLtvJpRzHQpA0QPVsj+RnVW/cuKXVq3378l4mlul5zHqIRZVrbNz65vjZ/s+m2Ic0RDWvoPLJaxTzKCbPQZdbTPrCWD/FzC/s5VeKchwLQdIQ1SM9yyHxcItMj46NWz7Vx1xlin0ecDaHH+6VpuvrvffDD49mXlHmoZxqMc+SW5jHVSnTUGn7bCKPdX7Uq6sr3/rORU3ZVaQUTWJhNjemm1ccmvWiVIt5ltzi0Ixfrm6tUkrkMcijY0tBTdk1oJgmsaAHZZjNjenmFYdmvSjVYp5ziUNQKrc4NOOXq1urlFLzmKj1x23fU2CuIommmkQpNmgTTZxKv4XmoZLVYp4T4rTvSXDVsM/Ged8LPTA7534AnApsApYA3zKz18Jejmwtcb1fvrWPOJV+C81DJavFPCfEad+T4Kphn43zvhcoMDvnegBjgUagGXgKmGhmq1OmGwFcDuxsZk3OuZ8CvwYOCzPR1SZTv2M+l8ck95lccUV+y89W+i1HM2McmvUgWN7DWj9xyXMQYe4T1VDzgtpsjq+kfTadWO976S5uTn4B2wBzgLuA9kBnvMD8tzTTHgKsBXYDHHAb8ESuZdTyDUYyPWggnxtKhHGLyHQ3OKimmwzkK0jea3H9RHVLxjjc7KFQtbgfVIty73tkuMFIkBrzocBgYKSZrQfWO+euBl5wzvUzs7eTpp0FvAe8ASwFegInFFd0qG6ZbheXqYkluWSefItIKO66vGoelFRIbSZI3pOnWb8exo71XpW4joKKYp+o9JpXtRwnlaTaW6ry6WN2Gf5Odh+wEdgF+BSYDNzvnNvHzD5oNTPnzgXOBejbt28eyagumZpT0n2WOljhhhu89/Xrt9zJJswmmVg39QRU6ACPIHlPTJNY/08/DVOnxmsQSdiqYZ8Im9ZJacV50FZYggTmqcArwA+dc2PwmrMnAE8l15adc52Bk4BTzexj/7MrgQuAE4Ebk2dqZrfhNXUzdOjQ8l9MXSaZBlGk+yy1ZJ54SEFU1+XV8gCPIHlPTDN2rBeU43wnobBUwz4RNq2T0qqFFopANxhxzvXEG/w1HDC2DP5amTRNA7AS+JqZPeJ/5oDlwHfN7I5M86+1G4xka4bJ9V3U91quNqW66Uq1l+BF4qKajrdMNxgp6s5fzrmuwM7A22a2yjl3L9AP+IKZrXTOfR+4DBhkZp9mmk8tBeZsO1WQHa6QAFtNO3IhSlEoqdWCj0g5VMvxFtWdv0YADwOn+O9j8GrWLzjnmoGPgRHZgnKtydYME6SJJjFYIZ871tRC0082mQZ4hHlwx3UQSa2rlhO4tFbtx1uxgXkucCneaGzMbA1eDfmyIudbtbINFAk6iCTfGrAGp2yt1lsRaoG2sVSqogKzmb0F/CSktNSEbANFgg4iybcGrMEpW6v1VoRaoG0slUr3yi6DbM3RQZpoCqkBx6npJw7Ni2pFqH7axlKpFJjLpJhmtkquAcelebGS16EEo20slUqBuUyKbWaLUw04H3FqXqzUdVhrimlh0TaWSqTAXCa12sxWq/mWwsSlhUWklBSYy6RWm9lqNd9SmDi1sIiUigJzGdVqM1ut5lvypxYWqUUKzCISW2phkVqkwFxCxQxiyfe3cbgkKa60biqLWlik1igwl0ixD6DI57caMJOZ1o2IxF1duRNQK9INYonqt8Usq9pp3YhI3Ckwl0hiEEt9ff6DWPL9bTHLqnZaNyISd0U99jEstfLYR/Uxx4PWjYjEQSTPYw5LrQRmERGRhEyBWU3ZIiIiMaLALCIiEiMKzBFIPM5x+vRyp6Rw1ZAHEZFKpOuYQ1YN18lWQx5ERCqVaswhq4brZKshDyIilUqBOWTVcJ1sNeRBRKRSqSk7ZNVw0/1qyIOISKXSdcwRStzIont3aGpSkBMRkS0yXcesGnNEEgOo1q+H5maoq4P27TWQSkREslMfc0QSA6iam73/m5s1kEpERHJTjTlEyfdgTgygSq4xayCViIjkosAcknTX/iYGUKmPWUREglJgLkJyDTndtb9XXKFALCIi+VFgLlBqDfmGG7z3xP9qshYRkUIoMBcotYbc1KRrf0VEpHgKzAVKDO5KriE3NoYfkJObyxXsRUSqnwJzgUpxdyw9TEJEpPYoMBchihpysnQDyhSYRUSqm24wEmN6mISISO1RjTnG9DAJEZHao8Acc1E3l4uISLyoKVtERCRGFJjzMH06TJ7svYuIiERBTdkB6dIlEREpBdWYA0p36ZKIiEjYFJgDSr50qb4eFixQk7aIiIRPgTmgxKVL55wDzsHtt3tN2wrOIiISJgXmPDQ2Qt++sGmTmrRFRCQaCsx50t24REQkShqVnSfdjUtERKKkwFwA3Y1LRESioqZsERGRGFFgFhERiREFZhERkRhRYBYREYkRBeYA9PAKEREpldBGZTvn+gAvAWuB5f7H2wBdgAvM7I9hLauU9PAKEREppUA1ZudcD+fczc65mc65l5xzk5xzHVMmWwbsAPzLzIaY2RBggv/Z2nCTXTp6eIWIiJRSzsDsnNsGmAJ0BD4PHAkMAx5Jns7MVgFvAwuSPu7mvy8JI7FRS9dkHeROX2rqFhGRsARpyj4UGAyMNLP1wHrn3NXAC865fmb2dmJCM9sj5bcVE5gzNVnnutOXmrpFRCRM+fQxuwx/Z1MxgTldk3UiwGa701e234mIiOQrSB/zVOAV4IfOufbOuc54fcdPJdeWM0gE5mWpXzjnznXOzXDOzfjss8/ySnQUCn04hR5qISIiYXJmlnsi53oCY4HhgAFPARPNbGWO3/0FOMTMumSbbujQoTZjxoygaY7M9OmFPZyi0N+JiEjtcs7NNLOhW30eJDBnmWlXYGfgbX/wV+r304AdzGy3bPOJS2BOUKAVEZGoZQrMxV7HPAJ4GDjFf0/VnQroX06mwVwiIlJOxd75ay5wKTArw/dfAE4rchkllTyYa/16GDtWl0GJiEjpFBWYzewtM/uJmb2T4fv3zOyNYpZRaonBXHV10NwMTz/t1aAVnEVEpBR0r+wUieuWjzpqS3Auyx2/dNcSEZGaFNq9smOlyNFbjY1eE/bUqVv6mkt6GZQ6ukVEalb1BeaQglquO35FSnctERGpWdUXmEMMatnu+BWpREd3WarrIiJSTtUXmJODWn09LFjg1aIrqcZZ1uq6iIiUU1E3GAlL6DcYmT4d7r0X7roLNm1SP62IiMROphuMVOeo7MZG6NvXC8p6kLKIiFSQ6gzMoKdLiIhIRaq+PuaE5H7a7t231JjVnC0iIjFWvYEZtgRhXRMsIiIVonqbshPSXT4lIiISU9UfmNXXLCIiFaS6m7JBfc0iIlJRqj8wg/qaRUSkYlR/U3aC+ppFRKQC1E5gVl+ziIhUgNpoygbdf1pERCpC7QRmKOPjokRERIKprcCcMH26as4iJdDc3MyHH37I6tWry50UkZJq27YtPXv2pHPnznn/tvYC8/TpGp0tUiKLFy/GOcdee+1FXV3tDGmR2mZmrF27lo8++ggg7+Bce0dK8ujs9eth7FgvWItI6JYtW0avXr0UlKWmOOfo0KEDvXv3ZtGiRXn/vvaOlsTo7Lo6aG6Gp5/2atAKziKh27x5M23bti13MkTKoqGhgY0bN+b9u9oLzInR2UcdtSU467pmkcg458qdBJGyKHTfr73ADF5wHjsW2rfXdc0iIhIrtTf4K0HXNYtIGu+99x6vvPIKPXv2ZPvtt6dnz5507Nix5bvOnTvT0NBAQ0PDVr9duXIl3/72tzn77LM59NBDt/p++fLljBs3jp49e7aa/7Bhw7L2w5sZt99+O926dWt5de3alT59+rB8+XJWrVpFz549adu2LfX19S2/mzZtGs8++yxdu3Zl1KhR9OrVC4B3332Xjh070rNnTwD+9a9/sXHjxpb09OjRo6UL4tNPP2XDhg306dOnVSV/4h0AACAASURBVA3woYceYujQoey2224tn7399ttsv/32tG3blg4dOuSz2iWZmZX9dcABB5iIVJ/XXnut3EnI269+9SsDbMSIETZy5EgbOnSonX766WZmNmDAADvppJNs0KBBduKJJ2712+uuu84AmzBhQtp5v/766wbY8ccfb5MmTbJLL73Uzj77bGtubs6apiVLlhhgBx54oF166aV2xhln2HHHHWeffPKJ/ehHPzLAxo4da845W7ZsmZmZjRs3zgAbNGiQ9erVy7p3725z5swxM7O99trL9t9//5b5H3zwwbbtttval770JTv44INtn332sYceesjMzMaMGWOArVixomX6+fPnW5s2bax///6t0t6hQwf77ne/a506dbJLLrkka5523nlnO+WUU7JOUw2yHQPADEsTE2u3xiwiksaSJUsAuOmmmxgwYAAAixYtorm5mcWLF9O1a1eWLl1Kly5dWv1uxYoV/OxnP2O77bbjoosuyjrvfffdl7POOosePXoEGrGe+N2RRx7JpEmTAFi6dCkdOnRg8eLF1NfXs3HjRpxzdO7cmfnz5zNu3DhuuOEGvvOd77B27VpGjhzJd77zHZ599lmWLl1Knz59Ws1/jz324PHHHwdg48aNtGnTpmU59fX1dOrUqWX6CRMmsGnTJq699lo2b97M8uXLaWhoYM2aNXTq1ImVK1dutX5SLVu2LOc0tao2+5hFRDJIBMFTTjmFIUOGcPDBB7PHHnuw//77s2jRopbA3LVr11a/u/HGG1myZAmbN29uCVyZ5v30008zevRoDjjgAH7yk58ETlOPHj1aPvvlL3/JIYccwh133EHXrl1bAp1zjtmzZ9Pc3MxZZ50FeKODTzvtNGbOnAl4QTE5/UuWLOGtt95i4MCBDB8+nM6dOzN48GAGDRrEk08+2Wrat99+m9/+9rcAvPHGG3z44YeMGjWKoUOHAlsGPKWun2TNzc2sWLGiVWB+9tlnOfjgg9l9993Zf//9ufjii1m1alXL92+++SaXXHIJ++23H/vttx9vvvlmy3czZsxgzJgxDB48mH333ZeVK1fmXKdxpsAsIvE3fTpMnlySyxoTQXDWrFnMmDGDP/7xjyxcuJDp/rK33XZbVq9e3SrwJGrL3bp144033mDBggUcccQRLTeYSJ332LFjmTJlCv/973/5/ve/HzhNyYH56quv5qWXXuKoo47aqrCw4447AvDyyy+3TD979mx69+7N6tWr2bBhw1aB+dhjj+WVV17hmWee4e2332bu3LnMnTuXPfbYo9W048ePZ9OmTfzqV7/ixRdfZMyYMTz88MM88sgjrdKcLTAvX74cM2uZ5vnnn+eoo45i4MCBzJs3j+eff5558+YxatQoAN555x2GDh3Kq6++yjPPPMPs2bPZa6+9AK8fvbGxkbVr1zJt2jTmzJnTqnZfiWq6KVt35hSpACW+W9+SJUto164dzz33HE1NTS2vRO0zITnw3H333SxdupSJEyfSu3dvfv/73/PLX/6SadOmccopp7RM19TUBMDDDz/M3/72t5Z5X3PNNRx00EFZ0wTw2muv8Zvf/IbFixezePFidt5555bab3JgHj58OIceeignnXQS559/Pu+//z533XUXd955J0uXLm2V/lWrVrFx40bWrl3LX/7yl5Y09e3bl5NPPplly5bRvXt3AN566y0eeOABBg4cyHnnncd5553H5MmT+e53v8u3vvWtjOsnVSINiRrz9ddfT6dOnfjpT39KXV0dDQ0NXHLJJYwcOZKZM2fy7rvvsmrVKgYOHMh2223Xal7Tpk1j06ZNDBkypGWQXqWr2cCsO3OKVIh0z1KP8GDdZZddOOGEE3j00UdbRk8PGDCA5cuXt/S7QuvAc9FFFzFo0KCW5lyACy64YKt577vvvvzoRz9qNSK7Z8+efO5zn8uapi5dunDaaaexadMmlixZwg477MC+++7LbrvtxkMPPbRVYHbO8de//pVx48bx2GOP0aVLFx588EG++tWv8tprr9GmTZuWadesWcPIkSPZbrvtePrpp1vS1bt3bwDWrl3bMm3v3r351a9+xa677trSZH3llVfS3NzMlClTWvWXZwvMy5YtazXNvHnzGDRoENtuu23LNO3btwe8pvNjjz2WE044gd///vfcfffddOjQgf79+/Pggw/yta99jSeffJLrr7+eCRMm0LFjR4YNG8aDDz5YuTe3STcirNSvcozKnjTJrL7eDLz3SZNKngSRqhfKqOxp08waGrwDtaHB+79MmpubbcOGDfbxxx/bqlWrWj6fNWuWHXvssXbwwQfboEGDrH///jZgwABLPbf9+Mc/tqOOOsoOPPBAGzBgQMt0mUZxB7Vp0yZbunSpLVy4MK/fBLVx48ac05x66ql22WWX2erVq+3DDz+0devWZZx2ypQpBtiTTz5pZmZf+MIX7LDDDms1TWJ0/Isvvtjq882bN9sZZ5xhwFb718aNG23EiBHWpk2bVqPIy6mQUdllD8pWpsAco2NdpGqFdrnUtGle6TmmB+rq1avtnXfesaampqxB7JNPPrEPPvjAVqxYkfMSqUqSCLRf/vKXA03/8MMPG2AvvPCCmZn985//tA4dOrQE6k8//dT69etnI0eO3Oq3ixYtsp133tlGjRq11XdvvfWWbbfddva9732viNyEq5DAXLODvxL3F5kwQc3YIrHX2AhXXBHbA7VDhw7suuuudOvWrVVzd6oddtiBPn360KlTp6q6VenYsWNxzjFnzhweffTRnNMnmrL/9Kc/AfA///M/PPvss/z4xz9m33335YgjjuDEE0/kz3/+c8tvNm3axB/+8AeGDx/OV77yFR544IGW79atW8ett97KiBEjuOyyy/jxj38ccg5Lq2b7mME7xmN6nIuIVIQpU6YwdepUTjrpJK6//nrOOOMMHn/8ce68886Mvxk8eHBLX3XCgQceyJQpU9JOv2LFChobGzn00EN5/PHHW64vB69/+itf+QrHHHMM06ZNY6eddgovc2VS04FZRESK079/f66//nqOOeYY+vXrx3PPPcdLL72U9TfDhg1j2LBhgZfRuXNnXn311bTf7bHHHhm/q1QKzCIiUrAdd9yRyy67rOX/urq6rJd+SW4128csIiISRwrMIiIiMaLAHEQJbwcoIiK1TX3MuegWYSIiUkKqMeeS7naAIiIiEVFgzuXww72acn2993744eVOkYhExMxYuHAha9as4eqrr2bgwIGsWLGi5fuFCxfywQcfeLdNTGPlypWcfvrpTJ06NfAyp0yZwv3338+TTz7Jiy++yLx581i5ciVmxrx581i9ejVr165t9ZuFCxdyyy23MHHiRKZNm9by+ZIlS3j//fdbHjn5/vvv8/jjj/Piiy/y7rvvsnr16pZp161bx/z581mzZk2rec+ZM4e///3vrfL46aef8uGHH7Ju3Tqam5sD500KlO52YKV+leOWnHmJ+e0AReIqtFtylsjSpUvtgAMOMKDl1adPHxswYIA99thjdtZZZxlga9asSfv76667zgC77rrrAi/zhBNOsLZt29oPfvADGzNmjI0aNcruueceW7RokQE2duxYA+wXv/iFmZn997//tW7dulmvXr1s0KBB5pxrWd7kyZMNsJdfftnMzG6//XYD7LDDDrMRI0bYfvvtZ6NHjzYzsxdeeMEAu/HGG1ulZ8SIEa1ul2lmdv7551u3bt3swgsvtK5duwZfoVLQLTnVxxyEbhEmUhO6dOlChw4d2Gefffj1r38NwJgxY6irq+P444/n7rvvpn379jQ0NGz128Qzmbt27cpFF10UeJlLliyhR48ejB8/HvBqsuvWreOTTz7ZKm0AF198MXvvvTdPP/00DQ0N3HjjjXz3u99l9OjRWz3SMfG4yJtuuonBgwcDsH79eoCtpgV47rnneOaZZzjmmGM46KCDaGpqonPnzixevLjlCVaJdJTTkiVLmD17NkOGDMn6FKtKpaZsERHfypUr+fe//8348eM55JBDOOSQQ5g4cSJz585l6dKlLF26lObmZkaPHs33vvc9Fi5c2PLbG2+8kSVLlrBx40YmTpzI5s2bAy0zEZgT5s6dy/HHH8/xxx/farpEAJo5cyajR49uKRycc845bN68mdmzZ2cMzKeccgpDhgzhiCOOYJtttmHQoEGMGTOm1bQA11xzDeDdy/rjjz/m2muvZfjw4TzxxBNbPVoymzvuuIO99tqL/v37c+CBB3Lvvfey22678cMf/rBlmieffJIDDzyQXXbZhf32248xY8a0pB/gzTff5IQTTmDHHXdk//3357jjjuO1114DYMaMGRx55JFMT7pS5vTTT6dnz54A3HbbbRx77LE899xzLQWszZs3M2nSJHbffXf22WcfDjvsMG699Vb69evHvffe2zKf++67j4EDB7LHHnuw3377ccUVV7Bu3TrAK7i89dZbrfJ6xRVXZLyVaKEUmEVEfO3ataO+vr5VbfXjjz+mTZs2dOjQgaVLl7Lbbrvxgx/8gC984Qstzw9O1JZ79OjBm2++yfz58xkxYsRWtd50UgPzsGHDmDp1KjfddFOr6RIBcccdd+Tll19u+XzOnDmA96zkpUuX0rZtWzp27Ngyb4BZs2YxY8YMHnzwQVavXs3cuXP5/ve/32q+zzzzDP/617/44he/yOjRoznooIM48cQTmTlzJgMGDAgcmO+8807OOeccJk+ezOuvv84TTzzB9ddfz7vvvtvSn/3YY49x3HHHccQRR/Dee+8xe/Zshg0bxsSJEwGvb/zzn/88q1atYt68ecyaNYtx48Zx8cUX09zc3JKv5LQ0NTXRrVs3wCvc/O1vf+PUU09ll112AWDcuHGMHz+e3/72t7z66qvcc889XHPNNcyfP7+lT/6mm27im9/8Jueff37Lctu1a8ftt9/Oxo0b+d///V/OPffclv73pqYmfvvb34Z/p7N07dulfpW9j1l9yCKRCKuPuZSH6FlnnWUdO3a0yy+/3C6//HLr2LGjnXXWWWZmtvPOO9vBBx+81W9+8YtfGGCTJ09u9dkjjzySc3nt2rWz4cOH23333Wc///nP7aqrrrLzzjuvpX840cf8yiuvmJnXb+ycszPPPNPGjRtnvXr1ssMPP9yam5vtyCOPtJ49e7bMe9SoUVZfX2//+Mc/7He/+53dfPPNNn78eNu0aZNNmDCh1TONDznkEAPsP//5j5l5fdD77LOPNTU12Z577mlf/epXrX///nbyySdnzc+AAQO2Wkc33HCDAfbzn//czMwGDRpk3bp1s/Xr16edx4UXXmiAzZgxI+33t9xyiwH2+uuvt3zW2NhojY2NZuY9GxqwqVOnmpn3HO1tt93Wvv71r7eaz8UXX2yAPfroo7Zx40br2rWrDRw4MGPeHnjgAQPstttuMzOzcePG2TXXXJNtdaiPuSC6Tlkk1kp9iN5yyy3069ePP//5zzjnuPrqq7ngggsAWLt2bdo+1osuuohBgwa1ejBDkH7mDRs2cMIJJ9CrVy/eeecdevXqxQEHHECvXr2YM2dOq0dDJmqHZ599Nttuuy133HEHc+bM4Rvf+AbXXnstzjnWrl3bqha588478+Uvf5lHHnmE7bffnp49e7LHHntgZqxZswbnXMv0EydO5IUXXmjJw0EHHcTLL79MXV1dy3yD1Jjfe+89Bg0a1OqzXr16AdC9e3cA3njjDYYMGUK7du3SzuONN94AaPUUqWSJGvN2223X8llTUxP9+vVr+btv374ccsghACxevJhVq1bRp0+fjOlatGgRS5cuZeTIkRnzNnr0aO6//34uu+wyjjzySO68805mzJiRcfqCpYvWpX6VtcY8aZJZfb0ZeO+TJpUvLSJVJowacxwO0c9//vO299572957722DBw+2o48+2p544omW72fNmmXHHnusHXzwwTZo0CDr37+/DRgwwIo9t23atMnWrVtnCxYssM2bNwf6zcaNG/Oafy733Xeffe1rX7PZs2fb4sWLbfHixVmnHzhw4FY15sRo9b/+9a9mZta7d2/baaedWk3z4Ycf2rBhw8zM7Otf/7oBNn/+/FbTHHrooTZ//ny78sorDbBFixaZmdmyZcusTZs2dtppp5mZ2bBhw2z48OEtv2tubrZOnTptVWM+++yzDbBXX33V1qxZY23btrVDDz201TT/+c9/7Mtf/nLL/wsWLLBOnTrZDjvsYBdeeGHWdWFWWI257EHZyh2Yp00za2jwjviGBjVni4QojMAct0P0scceM8Duvvvuls9Wr15tr732mjU1NeUVGONu48aNtuuuu9o222xjH3/8caDfJJraEwWXt956y3r16tXqEqzx48e3atpeu3atjR492ib5pa5nn33W6urq7Ktf/aqtW7fOzLyugZEjR5qZ2c0332yA/fvf/zYzs+9973sG2EUXXWRmZrvvvrt98YtfbJWuq666yhoaGmzWrFlmZvbiiy9aQ0ODAbZw4UIzMzvzzDPNOdfSBbFs2TI7/PDD7f777281r5tvvtnatGlj7733Xs71UfbADNwBzMz3d+pjFqlOldjHnMvvfvc7A+zPf/5zy2fr1683wM4+++yWzwYPHmxjx44tRxJDc8cddxhgnTp1sgsvvNBWr16d8zfNzc02YcKEluusTz75ZPvWt75lDQ0NNm/evJZpbrnlFuvfv7/169fPDjroILv++utbtQpMmTLFDjnkEOvdu7cNHz7czj33XGtqajIzL2CedNJJ1qtXLxs+fLhdddVVBti1115rZmZdu3a1b3zjG63StWHDBrvooouse/fuNmTIEDvjjDNs9OjRts0229iGDRvMzNuO1113ne2+++7Wv39/Gz58uP3mN7/ZKo+PPvroVvPPJLLADPQAbgZmAi8Bk4COaaabAnwUZJ4Wp8AsIpGotBuMBHHXXXdZmzZtWgYWmZktXLjQAOvRo4ftu+++NmzYMAPsggsuKGNKi5OoLTc0NNiCBQvsyiuvtL333rsluMbZU089lXHgWLGam5ttyJAhNnfu3EDTRzL4yzm3jR9wZwGfB9oDj/ivY1Im7wYsRUSkSp1xxhmcfvrpicoIsOVmHZdccglXXnklb775JnvvvXdF3/zCzLj++utZtmwZO+20ExMnTmTUqFHstNNO5U5aTkcddVRk8/7Tn/5Enz59GDhwYGTLCDIq+1BgMDDSzNYD651zVwMvOOf6mdnbSdN2Bbo4514FNuAF82vM7KOwEx5L06d7D7k4/HCN7BapYs65ViOmE4H5lltu4YEHHmDTpk307t2bXXfdtVxJLFrbtm055ZRTWn22//77lyk18dGxY8eWu7RFJZ/LpVyGv5N1AxYARwKLgRuBKc65/c1sTYbfVAdddiVSs/bff38+/fRTOnXqlPZ2nVI9jj766MiXEeTOX1OBV4AfOufaO+c6AxOAp5Jry865NkAn4EYz+9TMNgPjgL3wmsBbcc6d65yb4Zyb8dlnn4WRl/LS4yFFalb79u3p2bOngrKEImdgNrN1eDXgtcB04Fm8QWCj0sxrM7Ap6bON/nvbNPO9zcyGmtnQ7bffvoCkx4weDykiIiEI1JRtZouA81M/d851BXYG3jazVc65PwJjnHMPmdkq4BLgQ+D5ENMcT42NXvO1+phFWjGzVv2xIrUieYBgPoq9JecI4GHgFP/9DGA88KJzrhn4AG/Q2IqMc4iTYgdv6fGQIq3U19ezcePGjLdeFKlma9eupW3brRqMcyo2MM8FLsUbfY0/wOv7/quyaPCWSOi6dOnCp59+Su/evamr08PspDaYGWvXruWjjz5quR93PooKzGb2FvCTYuYRG+kGbykwixSlR48efPjhh7z55pvlTopISbVt25ZevXrRuXPnvH9bk0+XSttinRi8lagxa/CWSNHq6uro27dvuZMhUlFqLjBnbLHW4C0REYmBmgvMWVusNXhLRETKrOZGY+hyYxERibOaqzGrxVpEROKs5gIzqMVaRETiq+aaskVEROJMgRlvpPbkyd67iIhIOdVkU3Yy3fBLRETipOZrzHpao4iIxEnNB2ZdPiUiInFS803ZunxKRETipOYDM+jyKRERiY+ab8oWKYqG9ItIyFRjFimUhvSLSARUYxYplIb0i0gEFJhFCqUh/SISATVlixRKQ/pFJAIKzCLF0JB+EQmZmrJFRERipKYCs65sERGRuKuZpmxd2SIiIpWgZmrMurJFREQqQc0EZl3ZIiIilaBmmrLzurJl+nRdAiMiImVRM4EZAl7Zos5oEREpo5ppyg5MndEiIlJGCsypkjuj6+thwQJdXyUiIiXjzKzcaWDo0KE2Y8aM0OaX6CLu3h2amra8B+4ynj4d7r0X7roLNm1Sk7aIiITOOTfTzIamfl51fcyJLuL166G5GZwDM6irg/btA8bXxkYvsm/a1LpJW4FZREQiVnVN2Yku4uZm7/9Eg0Bzc55dxrq+SkREyqDqasyJeJquxpxXfNWTg0REpAyqLjAnx9OC+5iTZ6aALCIiJVR1gRkUT0VEpHJVXR+ziIhIJVNgFhERiREFZhERkRhRYBYREYkRBWaRQkyfDpMn63atIhK6qhyVLRIpPYFMRCKkGrNIvvQEMhGJkAKzSL50u1YRiZCaskXypdu1ikiEFJhFCqHby4lIRNSULRIHGuUtIj7VmEXKTaO8RSSJaswi5aZR3iKSRIFZpNw0yltEkqgpW6TcNMpbKsn06dpXI6bALBIHGuUtlUDjIUpCTdkiIhKMxkOURKiB2Tk33jlnzrlXnHP/dc79J8z5i4hIGWk8REkEasp2zvUAxgKNQDPwFDDRzFanTLq9/z7MzNaGlciqoz4aEalEGg9REjkDs3NuG2AKMAv4PNAeeMR/HZMy+fbAWmBHP5i/YWbLQ01xpVMfjYhUMo2HiFyQpuxDgcHA5Wa23sxWAFcDX3DO9UuZtgewDXAbcCnwvnPue2EmuOKpj0ZERLLIZ1S2y/B3slFAVzN7G8A5dyFwo3Numpm1utegc+5c4FyAvn375pGMMgqjCTrRR5OoMauPRkREkjgzyz6B15T9EjADGMOWpmwzs6Nz/HYA8CrwfTP7aabphg4dajNmzMgz6SWWrgkaCgvUtd7HXOv5FxEBnHMzzWxo6uc5a8xmts45dyTe4K/pgOEP/kpZQD/gVDMbn/Txtv77igLTHR+pTdD33gv33FNYX3Et99Goj11EJKtAl0uZ2SIzO9/M9jezA8zs/8xspXOuq3NuP+fctsAHwOnOudOcc3XOua54wXwx8Gh0WSiR1MsEQH3FuaR7YpL62EVEsir2zl8jgIeBU8zsYefcl4AbgZ8DG4DngUYzW1zkcsov9TIBaF1jVl9xa5lqxupjFxHJqtjAPBdv9PUsADN7HRhZbKJiK7UJWtfzZZauZpxYf1pvIiIZ5Rz8VQoVMfgrGw1m2pr6kkVEsip48JfkoACUnmrGIiIFUWAuVqYmW6nt0eciIgXS06WKpZu6i4hIiFRjLpaabEVEJEQKzGFQk2110qA+ESkDBWaRdDSoT0TKRH3MIunoDmW1Kd3d6kRKTDXmKFRDE2g15KEYukNZbZk+3bv//V13waZNaiWRslJgLkS2oFUNTaDVkIdiaVBf7Ujs7+vWQeKGS7r0sTRqvQKQgQJzvnIFrWq4rrka8hAGDeqrDYn9PRGUnVMrSSmoApCR+pjzlavvsRqua66GPIgElbq/n3eegkQplHIcR4WNHVCNOV+5+h7j3gQapOko7nkQCZP29/Io1TiOCqyZKzDnK8hBHNcm0Hx20LjmQSQK2t9Lr1QFogrsmlNgLkSlHsSZmo5UUyieBrGI5K8U59IKvMJCgbmWpO6g3btXXBMPEL8gWIFNZSI1owK7KhSYa0nqDlqBTTyxDILFrMe4FTJEqlGFtXIqMNea1B20wpp4YlmYKLSpLI6FDBEpOwXmWlaBTTxl7y9KV8MtdD3GsZAhlUOtLVVLgbnWVVgTT1kLE9lquIWsx3IXMqRyqbWlODEv1CgwS+UpV2EijBpu6gmh0losJB7U2lK4CijUKDCLBFVsDTfTCSFmJwWpAGptKVwFFGoUmEWCKraGWwEnhJKIeTNiRVBrS+EqoFCjwCySj2JquBVwQohcBTQjVgy1thSmAgo1CsxRUs1AklXACSFytdZqoHNAPMW8UKPAHBXVDCSdmJ8QAikm2NRSq4HOAeVXoQUjBeao1FrNQGpDscGmlloNdA4orwouGOl5zFHRM42lGoXxDN3GRrjiioo5SRas3OeACnsGcehK+bznkKnGHJVaqhmUW9Dmqgpt1gpVsesgjk3Rcd2ucb0ZTq2I474akAJzlKqhPzHugp6AdKIKZx0ECTalDJT55qnUQbySb4ZT6Sq4cqTAHHdxrQ3ERdATkE5U4a2DbMGm1AWgfPJUS4WzCq4thipowShm51kF5jirpRNJoYKegKr9RBXkxFKKdVDqAlA+eaqlwlkF1xZLLobnWQXmOCvHiSTKkmMU8w56AirViaocJe+gJ5ZSrINSF4DyyVO1Fs4y7XPqSgsmjgU2Myv764ADDjBJY9o0s4YGs/p6733atMpdXqnzUg7lyuOkSd4ywXufNKk0y81k2jQvDXHcxlGlrVx5roXjKmplXIfADEsTE1VjjrNCajjF1NiiLDmWolRa7n6icpW841YTLLamFuV2jKIWWc6m0GL2uXIfL3ERw2Z/Bea4y+dEUuwJIsoTfNTBIw79ROUKkDE8sRQsDtsxX+VsCi10n6vE9RylmDX7KzCXQqlKpsWeIKI8wUcdPOLQT1TOABmzE0vB4rAd81XOFotC97kw1nOm85pq4kVTYI5aKUumYZwgcp3giznoogwecWnOrZYAWS5x2Y75KHeLRSH7XFTPFldNPBQKzFErZQ0g6hNEnA+6cp8c46ZSay2Vuh0rrUBW7HrOdF6rxBaPD7xMIAAAEDlJREFUGFJgjlo5Lh+J6kAI+6ALO3hU2skxKnEuQAWh7VgaxaznTOe1SmzxiCEF5qhVag0gnTAPukoPHnGmWkvlthhUikzntWo635WRAnMpVEsNIMyDTsEjOrVea1GhrzQyndeq5XxXRgrMpRRmKb5cNYKwDrpaDx5RSleAqqUaZLUX+mppW9YoBeZSCbMUXw01AjV5RSu5ABWX/aVUAaWaC31RbMtqDPQVnicF5lIJsxRfLTUCNXnllnqCKeSEk+/+EsVJrZSFgzgX+opdt1EMwIxDoS1MVZAnBeZSyVaKz/dgreYaQbUp5kSceoK54Qa4+OL8Tzj57C9RndTCDChB1mkcC31hrNtijv106y15u6xfD2PHeq+4rLtSFETjKN0NtEv9qpmHWKS70X2hN1CP84MCxJO8bdu1MxszJr/tlfpwiqOPLvxhFUH3l6geiBHWgwIq+aENYa3bQo79TOst8XldnZeuurr4rNcg2zrMc2oZkOEhFmUPylZLgTmdch6sxcw3zgWDuKQteduCmXP5F76STzC33hr9CSfqJ4wVu13i9iStfJQzYGRbb9OmeYW+RHAudL2Gfdwlp7muzktj0AAcl3NADgrMcTRtmleLat++uIM1qgM+Vyk7jiXSOKUtkRbntgTnYmu6pTjhFLqMUqUtLtu3EHF9PGSx6zWK7ZKrNl/JhTRfpsCsPuZySe5vqq+Hc86Bb34zHgNCcs03zn04+aQt6pGbiUFI994Ld90Fmzbl3y+Y2ldair7TQpZRqgE3YQ3sqvTLDQtZbmK9de/uvSc+T/0+Lo+MTaRp7Fh4+mlobm497yoea6PAXC7JOzJA376Fj5SNagdNnm99PSxY4KUjzgdE0LSVMpA0NnqFrjiOEg5LuhNz4vMonlSmkcj5S+QxU95zrdcwz0FBC0aNjV5gnjp163mXYvR9uQpw6arRhb6AHYHe+f6uJpuyszUTFzKYIco+5nTN7VE2yRU77yC/z9XnVurm41QV0kfWIsr+8Cj7Liu0CbRgheY9zHNQIc3e5ToGI+42oRR9zMA9gAFt8/ldTQZms/QBIN2OkE8QiULUJ7LkPJSqDzFo/3kpBlwFTVvcJW/HMAc1RtV3GUZgqPQCVNB0h3kOqoSCUVgD4nLIFJgDNWU753oAY4FGoBl4CphoZqtTJu0GrDSzjf7vfgYcAhzkJ0KSpTYdZeqnydSkDLmb5MJoiomy6Tq1WfH006Pvv06skxtugKamzNd1btgAjzxS+v70IP11cbyzUer+XOw+M32614y5fv3W/YuJ73Otg3TT5NsEWk3PHi60+TfTOaCQdRD2tdhhS+Qpsd/V1ZW+yy5dtLbWteBtgDnAXUB7oDNeYP5bmmmnAe8l/f8EsCzXMmq2xpwq1/D/1CblMWOylzzDrG1EVTNILT2PGRNtmvMdnRrHGnOpa9SF1haL2WfSjchNvhY8aNNqGOspXQ0vU42qWmrWZsG6dAqtSReyPkq136e7TOvWWyPZfhTalA2MxGue7pn02UH+Z/1Spn0DmJX0/wvAO7mWocCcJNsOm08QSz1xpLsOMA7SHWz59FVlO/DT3dwjSDNa3PuYS9kUGLTJv9DgGySPdXVmBx6YX6E0dR5Bt3WuddCundlXvuKlJfUynkyFuHzWVVwCeNA0h7V/BMl3kEJArgAa5NguYeE8jMDcK+mz4RkC82fA00n/z8u4YDgXmAHM6Nu3b2gZrWpBg1hqbSNxHW2c7uqTLIrSc6abe2Q7yMI8KZaiNhnWiSLbSS3TTR7yKRyE0XKRGogzFUqTlxVmy0Nyi1XydelB1knQAkIY9zTIlPZ89rV8C/X51qTT/T7fQkC61pNcdy8LEnDTHQsRFoSLCczbAHPTNGX/I2U6B2wCHkr6rAmYCnTOtgzVmPOQb8myrs6sX7/oBjGUK5jlOlgSB2G6m3ukKzWHeVIMMyBkW0aQGkKueSTyne6klu375JNattuNZsprrrs6JecxU5BNtx3zaX3J94SbqbCXq5aYK12Z9tUxY4pvuSmk5hpGoT5TEE0n3yCerUsv2418UpeTeovbbIW9uNWYvd/SE7gFmAXMBH4IdEqZpotfi54PPO0HcwM+AY7ONn8F5pCVqikm6MEX5ISSbzALkqcgATdbAC9UrhNNWCNcizlhpMt3alBI3rYHHpi+PzXX+s2U16C1nNQ0Z1s3+a7XbOsvXcEnyP6eqcCUqZCRum4TwbBduy3rNbn5PN9tXUzho9hCfbr9I11BMt/9OFOXXrE15mzdI2FWQJIUFZgzvYCuwH7AtkAH4AT//+7Adn5g/nWu+SgwRyBdbSLsHStXDSKx3CAHXSHBLGiegtaaCrmfdablFVJjDhIokj8rZp2k5ju5aTafpuOgLReZ8hTmOIiw1mu2QkMYhcxs6z4R8NPVAnMVHPMtfARJe7GF+tRA37Zt8IJQ0DQmb5di+pgjrBlnElVgHuUH35PTfLeb/911ueajwFyhgtQ2g5bYcx1sUfa/BW1yy3e++fYx56pd5go4+ZxE0+U7U+0wW1AKcjLLti4KqTlnk896zSRd4MyntlhIN0tqoSRTi0amgmO2/TjfQnmYhfrkdLVpk732nc+xGFENNrL5ZhBVYN4T+D6wW5rvOgLHAv1zzUeBuQzC2gHTNVcVWmJPV3rNdLlMmEp8MGZNR7610uS051uDLqTwUMx02X4f5c0cCq01FlpYCFpYCdLNkjxNtv0/ipafsCQXsPNpSYhTHiISSWAO66XAXGJBa0P5zrPQAJBOsbWWSlVMc2TYzZClFHUzYqG1xkIH14VZqAk6TdhjJaIQpPUk7nkIkQKzbJFp8EQYJ8Uwa+JhNnFWukJO9Pk24ZZbXFouKlWQWnjcVUMe8pApMOvpUrUo9ZZ4EM5tJ8O8RWHqY+pSb51Za4I+USns22KWUrkeiVgtquFJZtWQhxAoMNei1PvlAtxzT/En8LCfyaoTdXFK8Vg8iZ9qOG6qIQ9FUGCuVak7fhgn8Dg/p7lW1fgJTqQSKTCLJ4wTuGpoIiJFU2CWcKmGJiJSlLpyJ0BERES2UGAWERGJEQVmERGRGFFgFhERiREFZhERkRhRYBYREYkRBWYREZEYUWAWERGJEQVmERGRGFFgFhERiRHnPRKyzIlw7jPg/ZBn2wNYHPI8y0V5iSflJZ6Ul/iplnxAuHnZ2cy2T/0wFoE5Cs65GWY2tNzpCIPyEk/KSzwpL/FTLfmA0uRFTdkiIiIxosAsIiISI9UcmG8rdwJCpLzEk/IST8pL/FRLPqAEeanaPmYREZFKVM01ZhERkYqjwCwiIhIjCswSOufcc865dc65//qvW8qdplrmnNvOObe3c65DudNSLOUlnqopL3FQVYHZOdfDOXezc26mc+4l59wk51zHcqcrCOdco3NuqnNujnPudefcnc65HfzvFjjnViQFuqvLnd4ctgfmmNkQ/3V+4gvn3M7OuXudc7Odcy845y51zrUtY1ozcs591Tn3iXPujaR1P9//bIdK2C7OuceA14DXgd5lTk5RMuXFOfcl/3hPHDs/c8519r+rd841O+cWJ22nM8uUhRZZ8hL7fSpVurw4577nHyevJuXlPefcB/73sdsu2c7BJWdmVfECtgHmAHcB7YHOwFPA38qdtgBp74u3Uw/w/+8GvAK8ADhgLfD7cqczj/wsBp4E9gf2Bdr7n/cAPgSuwysUfg6YDdxa7jRnyMeXAANOT/rsNv+zhkrZLsAv/TR3T/psZ+Bef/2/AFwKtE36fhDwiH9M/Rs4E3+waJzyAgwDZgF9/P93Aj4FHvL/7+VPf3250x5wu2Tdpypou3zb//9/kqb5B/BpHLdLgHNwSY+XaqoxHwoMBi43s/VmtgK4GviCc65feZOW0/bApWb2GoCZLQHuBg4CBuIVOpY75w5yzg1wztWXLaU5OOfqgK7A4cAVwA3AO865o4ATge2Aa8ys2cw+ASYDZzrnGsqU5GwWAvOBpqTPugHrgXoqZ7t0wzsJLgOvZQl4HliAV3g6Efg6cLP//Z7+938H9sM7yYwD/q/UCU+jVV7w9rVvm9mHAGb2AfAH4ETnXDu8YwtgtXPu8865PZxzrtSJziB1u2xLln2qwrbLR8BbwMqUaZb4f8dtu2Q7Bw+l1MdLuUsqIZZ4RuLtGL2SPhvuf9av3OkrID/n+2k/0H9fDjwAvAS8AexX7jRmSXtvoHfS/4/gHZAX4h2o9Unf/S+wEWgod7oD5u0ZvJPOLpWyXfwTxpKk/8/xt0Nd0mdfS2wHYCLwWso8Lgc+jFteMkzzI3/b9MQrIBpeLfo+vCbX/wB945aXXPtUFWyXd4Dn/b9ju12S0ps4B19e6uOlDdVjKl7Tww+dc2PwmrMnAE+Z2dtlTVlhjgXWAG/iNaOsM7NFfo30ReBBYO8ypi8jM/so5aMpwEl4B95KYJxz7hq8E+f/AXeZ2drSprJgiVL/B1TOdkmuqSRzGf5OxwWYphQy5QVoabE5Gu+hOJ/h1WR2BZab2VK/ZWYeXpfEMdEnN6vUvBSyT1XEdkma5lX/7zhvl4TEOXiN/3/Jjpeqaco2s3XAkXh9NNOBZ4GZwKhypiso59yuzrld/Gadu/B2im+b2XIzW2BmiwDMrBkvb3s557qXM83pOOe+4pxLXefb+u9LgIPxTj6zgMeA3+H1R1WKbsBSM9tcQdulG62b4//ElgJSnT/AJbmAdC/Q1zl3rvPsCVyA149Ybql5wTm3p3/sHAH8GdgTOM88G83sPTNbCuDnbxreflhurfISYJ+qqO2SzG+S7wwktkPstkumczBewaikx0s11Zjxd+jzc04YT48DuwHP4dX89zSzd5xz5wGvmNnzSdNuC2zCK4TEzTvAY865981shnNuL7xt8k8zm+dP843yJa9o3YBZFbZduuH19wFgZp855w4GxuMVkDbgFZB+7n//pv/9WLwTzGp/2jtKm+y0WuXFNwuvWfF5/+9zzGwhgHNuLHCvmb2TNP22wIrok5pTq7zk2qcqcLsk64pXg1wCsd0uac/BACU/Xsrdjq9XS5/Ex8BzaT4/FpgL7OH/fyDeAIu7yp3mLHn5Et7oxCa8QP1joHO50xVCvtrj9TndWSnbBa9VrBm4v9xpiSIvQDt/m9yb4Tdj8GqdO/r/H4cXxK+NYV4qYp8Kkpc00+zpb6dr4rpdMp2Dy/GqqhpzhesKdHDOnYV3GdHngEVmNs5vOvmr35y1GG9wy0/Ll9TszOwvwF/KnY4IdPPfl5jZkxWyXbrg1VQyNjNWkHR56eq/b+/XOHfAO3ZeNrNbzOzXzrkuwDR/1PPHeIMQby1hutPZKi8VtE+lCrKPJbp3lgDEdLtkPAeXOiF6iEUMOOfa4NXCFgKf+K+FwPtm9m450yZb+NupH7DK/Mtz4s451x44AvjIzOaWOz3FSJcX59zngElsfezMN7OPy5XWXKp9u6SZZhtgd7xA91kp0xdE3M7BCswiIiIxUjWjskVE/r+9OqABAABAGNS/tTU+ByWAB2IGgBAxA0CImAEgRMwAECJmAAgZ/T3dLOd2HTcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_len = numpy.arange(len(acc))\n",
    "plt.figure(figsize=(8,6))   #그래프의 크기 셋팅\n",
    "font_path = \"C:\\\\Windows\\\\Fonts\\\\HMKMMAG.TTF\"\n",
    "font_name = matplotlib.font_manager.FontProperties(fname=font_path).get_name()\n",
    "plt.rc('font', family=font_name, size=14) \n",
    "\n",
    "# 학습 데이터셋의 accuracy는 파란색으로, 테스트 데이터셋의 loss는 빨간색으로 표시\n",
    "plt.title('테스트셋 오차와 학습셋의 정확도 비교', fontsize=14)\n",
    "plt.plot(x_len, vloss, \"o\", c=\"red\",  markersize=3,  label='테스트 데이터셋 loss')\n",
    "plt.plot(x_len, acc,   \"o\", c=\"blue\", markersize=3,  label='학습 데이터셋 accuracy')\n",
    "plt.legend() # 범례 출력\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
